{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U0Z3kRDUW5-"
      },
      "source": [
        "# LFM integration test and baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WideRkxOUW6D"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "import scipy #scipy.sparse.vstack,  scipy.sparse.csr.csr_matrix \n",
        "import sklearn#sklearn.base.BaseEstimator, sklearn.preprocessing.normalize\n",
        "import lightfm #lightfm.LightFM,    lightfm.data.Dataset\n",
        "\n",
        "import pickle\n",
        "import lightfm.data\n",
        "from model_pipe.utils import from_yaml\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDG1XyLAUW6G"
      },
      "outputs": [],
      "source": [
        "yaml_params = from_yaml('config.yaml')\n",
        "# данные учетных записей\n",
        "short_user_name = yaml_params['user']['spark']['short_user_name']\n",
        "hive_database = yaml_params['user']['spark']['hive_database']\n",
        "user_name = yaml_params['user']['oracle']['user_name']\n",
        "del yaml_params['user']['oracle']['passw']\n",
        "# база в Oracle\n",
        "db_name = yaml_params['user']['oracle']['db_name']\n",
        "# пути\n",
        "wrkon_path = yaml_params['paths']['default']['wrkon_path']\n",
        "hdfs_path = yaml_params['paths']['default']['hdfs_path']\n",
        "# название модели\n",
        "model_name = yaml_params['model']['name']\n",
        "model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UgD4pJMUW6I"
      },
      "outputs": [],
      "source": [
        "PATH_TO_DATA_TRAIN_OLD = '/data/isbagaut/intern/inb_vas_model_united_data_train_lgbm.csv'\n",
        "PATH_TO_DATA_TRAIN_NEW = '/data/isbagaut/intern/inb_vas_model_united_lfm_data_train_to_add.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBQw_RcZUW6J"
      },
      "outputs": [],
      "source": [
        "PATH_TO_TEST_DATA = '/data/isbagaut/intern/inb_vas_model_united_lfm_data_test_new.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hY2aBdSZUW6K"
      },
      "outputs": [],
      "source": [
        "PATH_TO_TEMP_TRAIN = '/data/isbagaut/train_temp_0401.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wo9eLRUKUW6L"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "df_train_old = pd.read_csv(PATH_TO_DATA_TRAIN_OLD, sep='\\t')\n",
        "df_train_old.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GagWxvo0UW6L"
      },
      "outputs": [],
      "source": [
        "df_train_old.shape\n",
        "df_train_old_cut = df_train_old[:500000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WftuysMzUW6N"
      },
      "outputs": [],
      "source": [
        "del df_train_old"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gr17wt0PUW6O"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "df_train_new = pd.read_csv(PATH_TO_DATA_TRAIN_NEW, sep='\\t')\n",
        "df_train_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1m5gGOIUW6P"
      },
      "outputs": [],
      "source": [
        "df_train_new.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5UZbMgjUW6P"
      },
      "outputs": [],
      "source": [
        "## Весь датафрейм не лезит, поэтому пользуем Chunksize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRKdPA5iUW6Q"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "chunksize = 5 * 10 ** 5\n",
        "for chunk in pd.read_csv(PATH_TO_TEST_DATA, chunksize = chunksize, sep='\\t'):\n",
        "    df_test_real = chunk\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DjJY0LSUW6S"
      },
      "outputs": [],
      "source": [
        "df_test_real.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqvhII_eUW6T"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "df_test_real = pd.read_csv(PATH_TO_TEST_DATA, sep='\\t')\n",
        "df_test_real.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFh2mI4aUW6T"
      },
      "outputs": [],
      "source": [
        "df_test_real.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0MND-tOUW6U"
      },
      "source": [
        "df_train есть конкатенация старого датасета и нового, для эксперементов возьмем только новый "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RocMkZfUW6U"
      },
      "outputs": [],
      "source": [
        "df_train = pd.concat([df_train_old, df_train_new], axis = 0)\n",
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMqqvWlUUW6V"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(PATH_TO_TEMP_TRAIN, sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjL04ZUpUW6W"
      },
      "outputs": [],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "putd6JXFUW6X"
      },
      "outputs": [],
      "source": [
        "del df_train['Unnamed: 0']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Crrx7NiDUW6Y"
      },
      "outputs": [],
      "source": [
        "del df_train_old_cut\n",
        "del df_train_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdEX_BKAUW6Y"
      },
      "outputs": [],
      "source": [
        "features = ['mapping_it_serv_hits_flg', 'mapping_user_education_flg', 'mapping_onb_psyhology_flg', 'mapping_interest_health_flg', 'mapping_books_usg_flg', 'mapping_onb_fashion_flg', 'mapping_onb_int_shop_flg', 'mapping_mftv_users_flg', 'mapping_interest_baby_toys_flg', 'mapping_travel_extra_flg', 'mapping_health_zog_flg', 'mapping_education_hits_flg', 'mapping_health_general_flg', 'mapping_insure_hits_flg', 'mapping_onb_games_flg', 'mapping_smart_device_flg', 'mapping_user_autopay_flg', 'mapping_user_bank_market', 'mapping_electronics_hits_flg', 'mapping_onb_dress_flg', 'mapping_user_audiobook_flg', 'mapping_tablet_flg', 'mapping_music_hits_flg', 'mapping_interest_cafe_flg', 'mapping_sms_healthy_flg', 'mapping_user_management_flg', 'mapping_mftv_general_flg', 'mapping_interest_mortgage_flg', 'mapping_user_detsk_intern2_flg', 'mapping_zg_v2_flg', 'mapping_travel_general_flg', 'mapping_user_detsk_intern1_flg', 'mapping_video_flg', 'mapping_dou_1gb_flg', 'mapping_paym_transf_forb_mod_flg', 'mapping_east_calls_flg', 'id_product', 'mapping_url_tinder_flg', 'mapping_clothes_hits_flg', 'mapping_vk_ok_hits_flg', 'mapping_cash_flg', 'mapping_tariff_vkl_flg', 'mapping_yandexmusic_streaming_flg', 'mapping_user_marketing_flg', 'mapping_onb_zoo_flg', 'mapping_onb_music_flg', 'mapping_press_web_flg', 'mapping_payment_out_3_flg', 'mapping_url_videogames_flg', 'mapping_phone_flg', 'mapping_interest_health_travel_flg', 'mapping_call_mts_flg', 'mapping_books_flg', 'mapping_detskie_tov_hits_flg', 'mapping_interest_health_zog_flg', 'mapping_user_finance_flg', 'mapping_zg_mod_flg', 'mapping_pers_gudok_mod_flg', 'mapping_travel_avia_flg', 'mapping_sms_supermrkt_flg', 'mapping_hypermarket_hits_flg', 'mapping_pets_hits_flg', 'mapping_enter_hits_flg', 'mapping_nfc_flg', 'mapping_health_mom_flg', 'mapping_onb_food_delivery_flg', 'mapping_rod_control_flg', 'mapping_health_travel_flg', 'mapping_zam_gud_flg', 'mapping_roaming_flg', 'mapping_user_bank_entertain', 'mapping_autopay_mod_flg', 'mapping_virt_cards_flg', 'mapping_sms_ticket_flg', 'mapping_beauty_hits_flg', 'mapping_eda_hits_flg', 'mapping_tourism_hits_flg', 'mapping_tv_channels_hits_flg', 'mapping_user_games_flg', 'mapping_books_hits_flg', 'mapping_sms_shop_flg', 'mapping_trf_warm_reception_flg', 'mapping_interest_beauty_flg', 'mapping_data_traffic_ptl70_flg', 'mapping_paym_trans_mod_flg', 'mapping_sms_banks_flg', 'mapping_banks_flg', 'mapping_dou_100mb_flg', 'mapping_user_national_recipe_flg', 'mapping_interest_clothes_flg', 'mapping_webmail_top8_flg', 'mapping_tariff_listen_old_flg', 'mapping_interest_jobs_flg', 'mapping_cvm_books_flg', 'mapping_is_male_flg', 'mapping_mou_flg', 'mapping_mou_out_more_2in_flg', 'mapping_streaming_audio_flg', 'mapping_sms_tv_flg', \n",
        "            'mapping_is_man_flg', 'mapping_user_news_sng_flg', 'mapping_onb_video_flg', 'mapping_travel_tour_flg', 'mapping_music_flg', 'mapping_onb_med_online_flg', 'mapping_mou_300_flg', 'mapping_payment_out_6_flg', 'mapping_specii_mod_flg', 'mapping_interest_entertain_flg', 'mapping_data_play_market_flg', 'mapping_megadisk_flg', 'mapping_up_cashback_flg', 'mapping_kino_hits_flg', 'mapping_is_top_user_flg', 'mapping_mftv_kids_flg', 'mapping_paym_transf_v2_flg', 'mapping_interest_movie_serials_flg', 'mapping_cash_hits_flg', 'mapping_audio_flg', 'mapping_onb_edu_online_flg', 'mapping_data_appstore_flg', 'mapping_url_stop_ad_flg', 'mapping_user_bank_cafe', 'mapping_onb_edu_tech_flg', 'mapping_onb_tech_flg', 'mapping_onb_fitness_flg', 'mapping_pets_sms_flg', 'mapping_mf_music_mod_flg', 'mapping_specii_v2_flg', 'mapping_card_visa_flg', 'mapping_cvm_audiobooks_flg', 'mapping_iphone_flg', 'mapping_marketplace_forb_mod_flg', 'mapping_streaming_video_flg', 'mapping_sport_hits_flg', 'mapping_user_bank_taxi', 'mapping_data_torrents_flg', 'mapping_antivirus_flg', 'mapping_tariff_listen_flg', 'mapping_dou_flg', 'mapping_travel_hotels_flg', 'mapping_is_woman_flg', 'mapping_audiobooks_mod_flg', 'mapping_onb_movie_flg', 'hist_conv_2m', 'mapping_home_hits_flg', 'mapping_user_sub_sport_flg', 'hist_conv_1m', 'mapping_other_tv_channels_hits_flg', 'mapping_onb_antivir_flg', 'mapping_mf_music_v2_flg', 'mapping_mob_com_flg', 'mapping_onb_books_flg', 'hist_hate_2m', 'mapping_interest_finance_flg', 'mapping_os_android_flg', 'mapping_user_prediction_flg', 'mapping_onb_payments_flg', 'mapping_avto_hits_flg', 'mapping_user_bank_oil', 'mapping_mf_tv_v2_flg', 'mapping_user_vas_flg', 'mapping_card_mastercard_flg', 'mapping_onb_home_flg', 'mapping_onb_cashback_flg', 'hist_hate_1m', 'mapping_user_tinder_flg', 'mapping_cvm_date_flg', 'mapping_sms_kids_flg', 'mapping_url_audiobooks_flg', 'mapping_press_flg', 'mapping_user_health_flg', 'mapping_accessory_hits_flg', 'mapping_os_ios_flg', 'mapping_shops_flg', 'mapping_mftv_film_flg', 'mapping_person_gud_flg', 'mapping_b2c_flg', 'mapping_interest_travel_flg', 'mapping_cvm_zam_gud_flg', 'mapping_interest_tech_flg', 'mapping_marketplace_mod_flg', 'mapping_interest_kids_flg', 'mapping_user_stop_ad_flg', 'mapping_mftv_moretv_flg', 'mapping_mou_in_more_out_flg', 'priority_offer', 'mapping_mf_tv_mod_flg', 'mapping_user_knowcalling_flg', 'mapping_onb_audiobooks_flg', 'mapping_onb_insurance_flg', 'mapping_rod_control_hits_flg', 'mapping_kitai_hits_flg', 'mapping_sms_carshar_taxi_flg', 'mapping_mou_out_more_in_flg', 'mapping_interest_around_the_world_flg', 'mapping_user_it_flg', 'mapping_pers_gudok_forb_mod_flg', 'mapping_mftv_tvshow_flg', 'mapping_sms_oil_flg', 'mapping_interest_mom_flg', 'mapping_file_dnld_share_top8_flg', \n",
        "            'mapping_travel_rzd_flg', 'mapping_auto_answ_flg', 'mapping_interest_edu_flg', 'mapping_url_press_user_psychology_flg', 'mapping_interest_auto_flg', 'mapping_onb_bcard_flg', 'mapping_url_edu_flg', 'mapping_cvm_health_flg', 'mapping_onb_flower_flg', 'mapping_cloud_services_top8_flg', 'mapping_interest_cooking_flg', 'prc_dou_diff', 'kino_hits_flg', 'pay_amount_r_max4', 'interest_health_flg', 'call_out_cnt_fav_max_ratep4', 'user_vas_flg', 'books_hits_flg', 'pers_gudok_mod_flg', 'ot2_3_flg_m3', 'user_national_recipe_flg', 'onb_video_flg', 'dpi_streaming_audio_s4', 'voice_out_onnet_dur_s4', 'hid', 'virt_cards_flg', 'revenue_sms_max12', 'data_torrents_flg', 'health_mom_flg', 'ot2_1_flg_m3', 'cvm_zam_gud_flg', 'ot2_3_sum_m2', 'onb_zoo_flg', 'perc_arpu_diff', 'streaming_audio_flg', 'user_stop_ad_flg', 'payment_out_3_flg', 'music_hits_flg', 'cvm_date_flg', 'user_finance_flg', 'voice_wrkd_day_rate', 'cnt_packs', 'sms_supermrkt_flg', 'cash_flg', 'mftv_tvshow_flg', 'appm_max4', 'sms_s4', 'beauty_hits_flg', 'area_homenet_cnt_s12', 'ot2_3_flg_m2', 'trf_warm_reception_flg', 'perc_arpu', 'area_homenet_cnt_s8', 'user_detsk_intern1_flg', 'conv_m3', 'sms_s2', 'it_serv_hits_flg', 'mftv_kids_flg', 'interest_movie_serials_flg', 'sms_kids_flg', 'video_flg', 'sms_tv_flg', 'sport_hits_flg', 'clust_subs', 'call_dur_out_fav_max_ratep', 'accessory_hits_flg', 'person_gud_flg', 'sms_in_s4', 'dpi_messenger_wa_s4', 'mf_tv_mod_flg', 'last_paym_date', 'arpu_diff', 'os_android_flg', 'url_tinder_flg', 'phone_flg', 'insure_hits_flg', 'tariff_listen_flg', 'dou_max12', 'travel_hotels_flg', 'zg_ot2_3_flg_m3', 'warm_reception_flg', 'subs_age', 'yandexmusic_streaming_flg', 'specii_mod_flg', 'up_cashback_flg', 'east_calls_flg', 'interest_kids_flg', 'lk_cnt_lift', 'mf_tv_ot2_1_flg_m3', 'onb_tech_flg', 'onb_edu_online_flg', 'all_mega_sms_cnt', 'dpi_gaming_s4', 'tariff_vkl_flg', 'days_in_fb_s12', 'mou_in_more_out_flg', 'ot2_1_flg_m2', 'mf_tv_cr_m3', 'interest_around_the_world_flg', 'marketplace_mod_flg', 'ot2_1_flg_w3', 'is_male_flg', 'zg_ot2_1_flg_m3', 'call_out_cnt_fav_max_rate4', 'hypermarket_hits_flg', 'travel_avia_flg', 'dpi_streaming_audio_s1', 'press_flg', 'audiobooks_mod_flg', 'mou_ratio_full_period', 'revenue_s8', 'pay_amount_r_s12', 'tablet_flg', 'perc_arpu_traf', 'mftv_moretv_flg', 'user_news_sng_flg', 'cell_homenet_cnt_s4', 'books_flg', 'cash_hits_flg', 'revenue_vas_max12', 'card_visa_flg', 'actual_balance', 'interest_health_travel_flg', 'voice_in_onnet_dur_s1', 'virt_pay_days_na_s12', 'chrg_voice_out_s12', 'rod_control_flg', 'press_web_flg', 'balance_on_fb_a8', 'prev_rtpl_dur', 'time_in_fb_s6', 'zg_mod_flg', 'dou_s12', 'antivirus_flg', 'ot2_3_flg_m1', 'tv_channels_hits_flg', 'mou_out_more_in_flg', 'onb_fitness_flg', 'last_data_date', 'onb_med_online_flg', \n",
        "            'interest_cooking_flg', 'zg_cr_m3', 'smartphone_flag', 'tourism_hits_flg', 'onb_payments_flg', 'pets_sms_flg', 'travel_rzd_flg', 'onb_insurance_flg', 'ot2_1_sum_m3', 'churn_rate_trpl', 'user_tinder_flg', 'interest_jobs_flg', 'cvm_books_flg', 'revenue_s4', 'avto_hits_flg', 'interest_baby_toys_flg', 'mg_voice_ratio', 'sms_max4', 'data_wknd_night_rate4', 'mf_tv_ot2_3_flg_m3', 'sms_oil_flg', 'call_dur_out_fav_max_ratep4', 'card_mastercard_flg', 'data_wrkd_rate4', 'interest_tech_flg', 'sms_out_max4', 'call_dur_in_fav_max_ratep', 'zam_gud_flg', 'streaming_video_flg', 'auto_answ_flg', 'onb_movie_flg', 'ot2_3_sum_w2', 'webmail_top8_flg', 'sms_in_min4', 'travel_tour_flg', 'onb_food_delivery_flg', 'health_zog_flg', 'cloud_services_top8_flg', 'call_in_cnt_fav_max_ratep4', 'total_actions', 'onb_games_flg', 'rtpl_rtpl_dur', 'ot2_2_flg_m3', 'inquiry_action_avg_time', 'mf_music_ot2_1_sum_m3', 'data_appstore_flg', 'client_age', 'chrg_homenet_sms_out_s4', 'prc_mou_diff', 'url_audiobooks_flg', 'call_out_cnt_fav_max_rate_1', 'mega_circle_dif', 'interest_mom_flg', 'dou_min8', 'clust_hid', 'smart_device_flg', 'ot2_1_sum_m1', 'url_press_user_psychology_flg', 'interest_entertain_flg', 'onb_music_flg', 'sms_in_s1', 'ot2_2_sum_m3', 'data_play_market_flg', 'appm_s8', 'pay_amount_r_max12', 'health_general_flg', 'onb_bcard_flg', 'last_rm_data_date', 'interest_finance_flg', 'revenue_mon_fees_s12', 'mou_m3', 'interest_health_zog_flg', 'user_detsk_intern2_flg', 'cr_m1', 'is_available', 'vas_ratio_chng', 'onb_dress_flg', 'date_sign_pku_on', 'mega_circle_prc', 'pets_hits_flg', 'mou_300_flg', 'travel_general_flg', 'sms_shop_flg', 'break_balance', 'dou_ratio_full_period', 'revenue_dou_max12', 'ot2_3_sum_w1', 'chrg_voice_out_s4', \n",
        "            'mg_voice_cnt_ratio', 'lifetime', 'vk_ok_hits_flg', 'url_edu_flg', 'time_in_fb_s8', 'clothes_hits_flg', 'eda_hits_flg', 'user_management_flg', 'user_marketing_flg', 'mftv_users_flg', 'user_sub_sport_flg', 'mf_music_mod_flg', 'interest_travel_flg', 'dou_min4', 'cell_homenet_cnt', 'home_hits_flg', 'os_ios_flg', 'dou_m2', 'revenue_wo_itc_vas_roam_ma3', 'chrg_mk_brt_s8', 'kitai_hits_flg', 'books_usg_flg', 'url_stop_ad_flg', 'onb_cashback_flg', 'detskie_tov_hits_flg', 'iphone_flg', 'user_it_flg', 'cr_m2', 'last_charges_date', 'pay_lag_days_a24', 'tariff_listen_old_flg', 'ot1_sum_m2', 'voice_wknd_day_rate', 'education_hits_flg', 'b2c_flg', 'time_in_fb_s2', 'filial_id', 'user_autopay_flg', 'url_videogames_flg', 'cc_out_dur_s4', 'dou_min12', 'sms_carshar_taxi_flg', 'dou_max8', 'onb_audiobooks_flg', 'paym_transf_ot2_2_flg_m3', 'data_traffic_ptl70_flg', 'amount_30_ratio', 'cc_out_dur_s1', 'date_auto_mf_on', 'mou_flg', 'cvm_audiobooks_flg', 'time_in_fb_s4', 'onb_antivir_flg', 'dou_m1', 'onb_int_shop_flg', 'banks_flg', 'onb_fashion_flg', 'paym_trans_mod_flg', 'file_dnld_share_top8_flg', 'dou_100mb_flg', 'user_games_flg', 'is_man_flg', 'time_in_fb_s12', 'cvm_health_flg', 'dou_1gb_flg', 'mftv_general_flg', 'mg_voice_cnt_ratio_chng', 'revenue_s12', 'music_flg', 'revenue_vas_s12', 'mf_music_cr_m2', 'chrg_mk_brt_s4', 'interest_mortgage_flg', 'electronics_hits_flg', 'last_mms_out_date', 'sms_healthy_flg', 'marketplace_hate_m3', 'onb_flower_flg', 'ot2_3_sum_m3', 'mou_diff', 'is_top_user_flg', 'enter_hits_flg', 'revenue_mou_max12', 'dvtp_dvtp_id', 'appm_max12', 'dou_flg', 'revenue_mou_s12', 'interest_auto_flg', 'interest_beauty_flg', 'user_prediction_flg', 'interest_clothes_flg', 'sms_in_max4', 'hate_m3', 'virt_pay_notif_cnt_s3m', 'cr_m3', 'user_health_flg', 'shops_flg', 'onb_psyhology_flg', 'cnt_of_fb_s12', 'ot2_1_sum_w3', 'travel_extra_flg', 'ot2_1_flg_m1', 'other_tv_channels_hits_flg', 'mf_music_conv_m3', 'mou_in_min4', 'amount_ratio', 'conv_m2', 'sms_ticket_flg', 'pers_gudok_cr_m3', 'is_woman_flg', 'sms_banks_flg', 'virt_pay_cnt_na_s3m', 'paym_transf_hate_m3', 'dpi_webmail_gmail_s4', 'onb_home_flg', 'appm_s12', 'voice_wrkd_night_rate', 'rod_control_hits_flg', 'onb_books_flg', 'last_sms_out_date', 'nfc_flg', 'ltv', 'payment_out_6_flg', 'revenue_wo_vas_roam_s12', 'mou_out_more_2in_flg', 'call_mts_flg', 'hate_m2', 'voice_in_onnet_dur_s4', 'paym_transf_cr_m3', 'autopay_mod_flg', 'mob_com_flg', 'mou_min12', 'mftv_film_flg', 'mf_music_ot2_1_flg_m3', 'interest_cafe_flg', 'interest_edu_flg', 'audio_flg', 'dou_23g_s4', 'last_mf_rm_date', 'mf_music_cr_m3', 'onb_edu_tech_flg', 'mega_sms_gains', 'last_4g_date', 'sms_s1', 'health_travel_flg', 'roaming_flg', 'user_audiobook_flg', 'region', 'sk_subs_id', 'id_offer']\n",
        "len(features)\n",
        "\n",
        "numeric_feats = ['prc_dou_diff', 'dou_min8', 'clust_hid', 'pay_amount_r_max4', 'ot2_1_sum_m1', 'time_in_fb_s12', 'call_out_cnt_fav_max_ratep4', 'call_out_cnt_fav_max_rate4', 'dpi_streaming_audio_s1', 'mg_voice_cnt_ratio_chng', 'revenue_s12', 'revenue_vas_s12', 'mf_music_cr_m2', 'dpi_streaming_audio_s4', 'sms_in_s1', 'ot2_2_sum_m3', 'mou_ratio_full_period', 'revenue_s8', 'appm_s8', 'pay_amount_r_s12', 'chrg_mk_brt_s4', 'perc_arpu_traf', 'pay_amount_r_max12', 'voice_out_onnet_dur_s4', 'hid', 'last_rm_data_date', 'revenue_mon_fees_s12', 'mou_m3', 'cell_homenet_cnt_s4', 'revenue_sms_max12', 'cr_m1', 'revenue_vas_max12', 'last_mms_out_date', 'is_available', 'actual_balance', 'marketplace_hate_m3', 'vas_ratio_chng', 'ot2_3_sum_m3', 'voice_in_onnet_dur_s1', 'mou_diff', 'virt_pay_days_na_s12', 'chrg_voice_out_s12', 'ot2_3_sum_m2', 'revenue_mou_max12', 'perc_arpu_diff', 'balance_on_fb_a8', 'date_sign_pku_on', 'mega_circle_prc', 'prev_rtpl_dur', 'time_in_fb_s6', 'appm_max12', 'dou_s12', 'revenue_mou_s12', 'break_balance', 'voice_wrkd_day_rate', 'dou_ratio_full_period', 'revenue_dou_max12', 'sms_in_max4', 'hate_m3', 'virt_pay_notif_cnt_s3m', 'last_data_date', 'cnt_packs', 'cr_m3', 'ot2_3_sum_w1', 'chrg_voice_out_s4', 'cnt_of_fb_s12', 'ot2_1_sum_w3', 'zg_cr_m3', 'appm_max4', 'mg_voice_cnt_ratio', 'mf_music_conv_m3', 'lifetime', 'mou_in_min4', 'amount_ratio', 'sms_s4', 'time_in_fb_s8', 'conv_m2', 'area_homenet_cnt_s12', 'conv_m3', 'perc_arpu', 'area_homenet_cnt_s8', 'sms_s2', 'ot2_1_sum_m3', 'churn_rate_trpl', 'revenue_s4', 'pers_gudok_cr_m3', 'mg_voice_ratio', 'sms_max4', 'data_wknd_night_rate4', 'virt_pay_cnt_na_s3m', 'clust_subs', 'paym_transf_hate_m3', 'dpi_webmail_gmail_s4', 'appm_s12', 'voice_wrkd_night_rate', 'call_dur_out_fav_max_ratep4', 'call_dur_out_fav_max_ratep', 'dou_min4', 'data_wrkd_rate4', 'sms_out_max4', 'sms_in_s4', 'cell_homenet_cnt', 'dpi_messenger_wa_s4', 'last_sms_out_date', 'dou_m2', 'hist_conv_2m', 'revenue_wo_itc_vas_roam_ma3', 'call_dur_in_fav_max_ratep', 'chrg_mk_brt_s8', 'last_paym_date', 'ltv', 'revenue_wo_vas_roam_s12', 'arpu_diff', 'hist_conv_1m', 'hist_hate_2m', 'ot2_3_sum_w2', 'hate_m2', 'hist_hate_1m', 'sms_in_min4', 'voice_in_onnet_dur_s4', 'paym_transf_cr_m3', 'cr_m2', 'last_charges_date', 'mou_min12', 'dou_max12', 'pay_lag_days_a24', 'ot1_sum_m2', 'voice_wknd_day_rate', 'dou_23g_s4', 'priority_offer', 'call_in_cnt_fav_max_ratep4', 'time_in_fb_s2', 'last_mf_rm_date', 'subs_age', 'total_actions', 'rtpl_rtpl_dur', 'cc_out_dur_s4', 'dou_min12', 'dou_max8', 'mf_music_cr_m3', 'lk_cnt_lift', 'inquiry_action_avg_time', 'mf_music_ot2_1_sum_m3', 'mega_sms_gains', 'client_age', 'chrg_homenet_sms_out_s4', 'last_4g_date', 'sms_s1', 'amount_30_ratio', 'cc_out_dur_s1', 'date_auto_mf_on', 'prc_mou_diff', 'all_mega_sms_cnt', 'time_in_fb_s4', 'dpi_gaming_s4', 'days_in_fb_s12', 'dou_m1', 'mf_tv_cr_m3', 'call_out_cnt_fav_max_rate_1', 'mega_circle_dif']\n",
        "len(numeric_feats)\n",
        "\n",
        "user_cols = ['prc_dou_diff', 'kino_hits_flg', 'pay_amount_r_max4', 'interest_health_flg', 'call_out_cnt_fav_max_ratep4', 'user_vas_flg', 'books_hits_flg', 'pers_gudok_mod_flg', 'ot2_3_flg_m3', 'user_national_recipe_flg', 'onb_video_flg', 'dpi_streaming_audio_s4', 'voice_out_onnet_dur_s4', 'hid', 'virt_cards_flg', 'revenue_sms_max12', 'data_torrents_flg', 'health_mom_flg', 'ot2_1_flg_m3', 'cvm_zam_gud_flg', 'ot2_3_sum_m2', 'onb_zoo_flg', 'perc_arpu_diff', 'streaming_audio_flg', 'user_stop_ad_flg', 'payment_out_3_flg', 'music_hits_flg', 'cvm_date_flg', 'user_finance_flg', 'voice_wrkd_day_rate', 'cnt_packs', 'sms_supermrkt_flg', 'cash_flg', 'mftv_tvshow_flg', 'appm_max4', 'sms_s4', 'beauty_hits_flg', 'area_homenet_cnt_s12', 'ot2_3_flg_m2', 'trf_warm_reception_flg', 'perc_arpu', 'area_homenet_cnt_s8', 'user_detsk_intern1_flg', 'conv_m3', 'sms_s2', 'it_serv_hits_flg', 'mftv_kids_flg', 'interest_movie_serials_flg', 'sms_kids_flg', 'video_flg', 'sms_tv_flg', 'sport_hits_flg', 'clust_subs', 'call_dur_out_fav_max_ratep', 'accessory_hits_flg', 'person_gud_flg', 'sms_in_s4', 'dpi_messenger_wa_s4', 'mf_tv_mod_flg', 'last_paym_date', 'arpu_diff', 'os_android_flg', 'url_tinder_flg', 'phone_flg', 'insure_hits_flg', 'tariff_listen_flg', 'dou_max12', 'travel_hotels_flg', 'zg_ot2_3_flg_m3', 'warm_reception_flg', 'subs_age', 'yandexmusic_streaming_flg', 'specii_mod_flg', 'up_cashback_flg', 'east_calls_flg', 'interest_kids_flg', 'lk_cnt_lift', 'mf_tv_ot2_1_flg_m3', 'onb_tech_flg', 'onb_edu_online_flg', 'all_mega_sms_cnt', 'dpi_gaming_s4', 'tariff_vkl_flg', 'days_in_fb_s12', 'mou_in_more_out_flg', 'ot2_1_flg_m2', 'mf_tv_cr_m3', 'interest_around_the_world_flg', 'marketplace_mod_flg', 'ot2_1_flg_w3', 'is_male_flg', 'zg_ot2_1_flg_m3', 'call_out_cnt_fav_max_rate4', 'hypermarket_hits_flg', 'travel_avia_flg', 'dpi_streaming_audio_s1', 'press_flg', 'audiobooks_mod_flg', 'mou_ratio_full_period', 'revenue_s8', 'pay_amount_r_s12', 'tablet_flg', 'perc_arpu_traf', 'mftv_moretv_flg', 'user_news_sng_flg', 'cell_homenet_cnt_s4', 'books_flg', 'cash_hits_flg', 'revenue_vas_max12', 'card_visa_flg', 'actual_balance', 'interest_health_travel_flg', 'voice_in_onnet_dur_s1', 'virt_pay_days_na_s12', 'chrg_voice_out_s12', 'rod_control_flg', 'press_web_flg', 'balance_on_fb_a8', 'prev_rtpl_dur', 'time_in_fb_s6', 'zg_mod_flg', 'dou_s12', 'antivirus_flg', 'ot2_3_flg_m1', 'tv_channels_hits_flg', 'mou_out_more_in_flg', 'onb_fitness_flg', 'last_data_date', 'onb_med_online_flg', 'interest_cooking_flg', 'zg_cr_m3', 'smartphone_flag', 'tourism_hits_flg', 'onb_payments_flg', 'pets_sms_flg', 'travel_rzd_flg', 'onb_insurance_flg', 'ot2_1_sum_m3', 'churn_rate_trpl', 'user_tinder_flg', 'interest_jobs_flg', 'cvm_books_flg', 'revenue_s4', 'avto_hits_flg', 'interest_baby_toys_flg', 'mg_voice_ratio', 'sms_max4', 'data_wknd_night_rate4', 'mf_tv_ot2_3_flg_m3', 'sms_oil_flg', 'call_dur_out_fav_max_ratep4', 'card_mastercard_flg', 'data_wrkd_rate4', 'interest_tech_flg', 'sms_out_max4', 'call_dur_in_fav_max_ratep', 'zam_gud_flg', 'streaming_video_flg', 'auto_answ_flg', 'onb_movie_flg', 'ot2_3_sum_w2', 'webmail_top8_flg', 'sms_in_min4', 'travel_tour_flg', 'onb_food_delivery_flg', 'health_zog_flg', 'cloud_services_top8_flg', 'call_in_cnt_fav_max_ratep4', 'total_actions', 'onb_games_flg', 'rtpl_rtpl_dur', 'ot2_2_flg_m3', 'inquiry_action_avg_time', 'mf_music_ot2_1_sum_m3', 'data_appstore_flg', 'client_age', 'chrg_homenet_sms_out_s4', 'prc_mou_diff', 'url_audiobooks_flg', 'call_out_cnt_fav_max_rate_1', 'mega_circle_dif', 'interest_mom_flg', 'dou_min8', 'clust_hid', 'smart_device_flg', 'ot2_1_sum_m1', 'url_press_user_psychology_flg', 'interest_entertain_flg', 'onb_music_flg', 'sms_in_s1', 'ot2_2_sum_m3', 'data_play_market_flg', 'appm_s8', 'pay_amount_r_max12', 'health_general_flg', 'onb_bcard_flg', 'last_rm_data_date', 'interest_finance_flg', 'revenue_mon_fees_s12', 'mou_m3', 'interest_health_zog_flg', 'user_detsk_intern2_flg', 'cr_m1', 'is_available', 'vas_ratio_chng', 'onb_dress_flg', 'date_sign_pku_on', 'mega_circle_prc', 'pets_hits_flg', 'mou_300_flg', 'travel_general_flg', 'sms_shop_flg', 'break_balance', 'dou_ratio_full_period', 'revenue_dou_max12', 'ot2_3_sum_w1', 'chrg_voice_out_s4', 'mg_voice_cnt_ratio', 'lifetime', 'vk_ok_hits_flg', 'url_edu_flg', 'time_in_fb_s8', 'clothes_hits_flg', 'eda_hits_flg', 'user_management_flg', 'user_marketing_flg', 'mftv_users_flg', 'user_sub_sport_flg', 'mf_music_mod_flg', 'interest_travel_flg', 'dou_min4', 'cell_homenet_cnt', 'home_hits_flg', 'os_ios_flg', 'dou_m2', 'revenue_wo_itc_vas_roam_ma3', 'chrg_mk_brt_s8', 'kitai_hits_flg', 'books_usg_flg', 'url_stop_ad_flg', 'onb_cashback_flg', 'detskie_tov_hits_flg', 'iphone_flg', 'user_it_flg', 'cr_m2', 'last_charges_date', 'pay_lag_days_a24', 'tariff_listen_old_flg', 'ot1_sum_m2', 'voice_wknd_day_rate', 'education_hits_flg', 'b2c_flg', 'time_in_fb_s2', 'filial_id', 'user_autopay_flg', 'url_videogames_flg', 'cc_out_dur_s4', 'dou_min12', 'sms_carshar_taxi_flg', 'dou_max8', 'onb_audiobooks_flg', 'paym_transf_ot2_2_flg_m3', 'data_traffic_ptl70_flg', 'amount_30_ratio', 'cc_out_dur_s1', 'date_auto_mf_on', 'mou_flg', 'cvm_audiobooks_flg', 'time_in_fb_s4', 'onb_antivir_flg', 'dou_m1', 'onb_int_shop_flg', 'banks_flg', 'onb_fashion_flg', 'paym_trans_mod_flg', 'file_dnld_share_top8_flg', 'dou_100mb_flg', 'user_games_flg', 'is_man_flg', 'time_in_fb_s12', 'cvm_health_flg', 'dou_1gb_flg', 'mftv_general_flg', 'mg_voice_cnt_ratio_chng', 'revenue_s12', 'music_flg', 'revenue_vas_s12', 'mf_music_cr_m2', 'chrg_mk_brt_s4', 'interest_mortgage_flg', 'electronics_hits_flg', 'last_mms_out_date', 'sms_healthy_flg', 'marketplace_hate_m3', 'onb_flower_flg', 'ot2_3_sum_m3', 'mou_diff', 'is_top_user_flg', 'enter_hits_flg', 'revenue_mou_max12', 'dvtp_dvtp_id', 'appm_max12', 'dou_flg', 'revenue_mou_s12', 'interest_auto_flg', 'interest_beauty_flg', 'user_prediction_flg', 'interest_clothes_flg', 'sms_in_max4', 'hate_m3', 'virt_pay_notif_cnt_s3m', 'cr_m3', 'user_health_flg', 'shops_flg', 'onb_psyhology_flg', 'cnt_of_fb_s12', 'ot2_1_sum_w3', 'travel_extra_flg', 'ot2_1_flg_m1', 'other_tv_channels_hits_flg', 'mf_music_conv_m3', 'mou_in_min4', 'amount_ratio', 'conv_m2', 'sms_ticket_flg', 'pers_gudok_cr_m3', 'is_woman_flg', 'sms_banks_flg', 'virt_pay_cnt_na_s3m', 'paym_transf_hate_m3', 'dpi_webmail_gmail_s4', 'onb_home_flg', 'appm_s12', 'voice_wrkd_night_rate', 'rod_control_hits_flg', 'onb_books_flg', 'last_sms_out_date', 'nfc_flg', 'ltv', 'payment_out_6_flg', 'revenue_wo_vas_roam_s12', 'mou_out_more_2in_flg', 'call_mts_flg', 'hate_m2', 'voice_in_onnet_dur_s4', 'paym_transf_cr_m3', 'autopay_mod_flg', 'mob_com_flg', 'mou_min12', 'mftv_film_flg', 'mf_music_ot2_1_flg_m3', 'interest_cafe_flg', 'interest_edu_flg', 'audio_flg', 'dou_23g_s4', 'last_mf_rm_date', 'mf_music_cr_m3', 'onb_edu_tech_flg', 'mega_sms_gains', 'last_4g_date', 'sms_s1', 'health_travel_flg', 'roaming_flg', 'user_audiobook_flg', 'region']\n",
        "len(user_cols)\n",
        "\n",
        "item_cols = ['mapping_it_serv_hits_flg', 'mapping_user_education_flg', 'mapping_onb_psyhology_flg', 'mapping_interest_health_flg', 'mapping_books_usg_flg', 'mapping_onb_fashion_flg', 'mapping_onb_int_shop_flg', 'mapping_mftv_users_flg', 'mapping_interest_baby_toys_flg', 'mapping_travel_extra_flg', 'mapping_health_zog_flg', 'mapping_education_hits_flg', 'mapping_health_general_flg', 'mapping_insure_hits_flg', 'mapping_onb_games_flg', 'mapping_smart_device_flg', 'mapping_user_autopay_flg', 'mapping_user_bank_market', 'mapping_electronics_hits_flg', 'mapping_onb_dress_flg', 'mapping_user_audiobook_flg', 'mapping_tablet_flg', 'mapping_music_hits_flg', 'mapping_interest_cafe_flg', 'mapping_sms_healthy_flg', 'mapping_user_management_flg', 'mapping_mftv_general_flg', 'mapping_interest_mortgage_flg', 'mapping_user_detsk_intern2_flg', 'mapping_zg_v2_flg', 'mapping_travel_general_flg', 'mapping_user_detsk_intern1_flg', 'mapping_video_flg', 'mapping_dou_1gb_flg', 'mapping_paym_transf_forb_mod_flg', 'mapping_east_calls_flg', 'id_product', 'mapping_url_tinder_flg', 'mapping_clothes_hits_flg', 'mapping_vk_ok_hits_flg', 'mapping_cash_flg', 'mapping_tariff_vkl_flg', 'mapping_yandexmusic_streaming_flg', 'mapping_user_marketing_flg', 'mapping_onb_zoo_flg', 'mapping_onb_music_flg', 'mapping_press_web_flg', 'mapping_payment_out_3_flg', 'mapping_url_videogames_flg', 'mapping_phone_flg', 'mapping_interest_health_travel_flg', 'mapping_call_mts_flg', 'mapping_books_flg', 'mapping_detskie_tov_hits_flg', 'mapping_interest_health_zog_flg', 'mapping_user_finance_flg', 'mapping_zg_mod_flg', 'mapping_pers_gudok_mod_flg', 'mapping_travel_avia_flg', 'mapping_sms_supermrkt_flg', 'mapping_hypermarket_hits_flg', 'mapping_pets_hits_flg', 'mapping_enter_hits_flg', 'mapping_nfc_flg', 'mapping_health_mom_flg', 'mapping_onb_food_delivery_flg', 'mapping_rod_control_flg', 'mapping_health_travel_flg', 'mapping_zam_gud_flg', 'mapping_roaming_flg', 'mapping_user_bank_entertain', 'mapping_autopay_mod_flg', 'mapping_virt_cards_flg', 'mapping_sms_ticket_flg', 'mapping_beauty_hits_flg', 'mapping_eda_hits_flg', 'mapping_tourism_hits_flg', 'mapping_tv_channels_hits_flg', 'mapping_user_games_flg', 'mapping_books_hits_flg', 'mapping_sms_shop_flg', 'mapping_trf_warm_reception_flg', 'mapping_interest_beauty_flg', 'mapping_data_traffic_ptl70_flg', 'mapping_paym_trans_mod_flg', 'mapping_sms_banks_flg', 'mapping_banks_flg', 'mapping_dou_100mb_flg', 'mapping_user_national_recipe_flg', 'mapping_interest_clothes_flg', 'mapping_webmail_top8_flg', 'mapping_tariff_listen_old_flg', 'mapping_interest_jobs_flg', 'mapping_cvm_books_flg', 'mapping_is_male_flg', 'mapping_mou_flg', 'mapping_mou_out_more_2in_flg', 'mapping_streaming_audio_flg', 'mapping_sms_tv_flg', 'mapping_is_man_flg', 'mapping_user_news_sng_flg', 'mapping_onb_video_flg', 'mapping_travel_tour_flg', 'mapping_music_flg', 'mapping_onb_med_online_flg', 'mapping_mou_300_flg', 'mapping_payment_out_6_flg', 'mapping_specii_mod_flg', 'mapping_interest_entertain_flg', 'mapping_data_play_market_flg', 'mapping_megadisk_flg', 'mapping_up_cashback_flg', 'mapping_kino_hits_flg', 'mapping_is_top_user_flg', 'mapping_mftv_kids_flg', 'mapping_paym_transf_v2_flg', 'mapping_interest_movie_serials_flg', 'mapping_cash_hits_flg', 'mapping_audio_flg', 'mapping_onb_edu_online_flg', 'mapping_data_appstore_flg', 'mapping_url_stop_ad_flg', 'mapping_user_bank_cafe', 'mapping_onb_edu_tech_flg', 'mapping_onb_tech_flg', 'mapping_onb_fitness_flg', 'mapping_pets_sms_flg', 'mapping_mf_music_mod_flg', 'mapping_specii_v2_flg', 'mapping_card_visa_flg', 'mapping_cvm_audiobooks_flg', 'mapping_iphone_flg', 'mapping_marketplace_forb_mod_flg', 'mapping_streaming_video_flg', 'mapping_sport_hits_flg', 'mapping_user_bank_taxi', 'mapping_data_torrents_flg', 'mapping_antivirus_flg', 'mapping_tariff_listen_flg', 'mapping_dou_flg', 'mapping_travel_hotels_flg', 'mapping_is_woman_flg', 'mapping_audiobooks_mod_flg', 'mapping_onb_movie_flg', 'hist_conv_2m', 'mapping_home_hits_flg', 'mapping_user_sub_sport_flg', 'hist_conv_1m', 'mapping_other_tv_channels_hits_flg', 'mapping_onb_antivir_flg', 'mapping_mf_music_v2_flg', 'mapping_mob_com_flg', 'mapping_onb_books_flg', 'hist_hate_2m', 'mapping_interest_finance_flg', 'mapping_os_android_flg', 'mapping_user_prediction_flg', 'mapping_onb_payments_flg', 'mapping_avto_hits_flg', 'mapping_user_bank_oil', 'mapping_mf_tv_v2_flg', 'mapping_user_vas_flg', 'mapping_card_mastercard_flg', 'mapping_onb_home_flg', 'mapping_onb_cashback_flg', 'hist_hate_1m', 'mapping_user_tinder_flg', 'mapping_cvm_date_flg', 'mapping_sms_kids_flg', 'mapping_url_audiobooks_flg', 'mapping_press_flg', 'mapping_user_health_flg', 'mapping_accessory_hits_flg', 'mapping_os_ios_flg', 'mapping_shops_flg', 'mapping_mftv_film_flg', 'mapping_person_gud_flg', 'mapping_b2c_flg', 'mapping_interest_travel_flg', 'mapping_cvm_zam_gud_flg', 'mapping_interest_tech_flg', 'mapping_marketplace_mod_flg', 'mapping_interest_kids_flg', 'mapping_user_stop_ad_flg', 'mapping_mftv_moretv_flg', 'mapping_mou_in_more_out_flg', 'priority_offer', 'mapping_mf_tv_mod_flg', 'mapping_user_knowcalling_flg', 'mapping_onb_audiobooks_flg', 'mapping_onb_insurance_flg', 'mapping_rod_control_hits_flg', 'mapping_kitai_hits_flg', 'mapping_sms_carshar_taxi_flg', 'mapping_mou_out_more_in_flg', 'mapping_interest_around_the_world_flg', 'mapping_user_it_flg', 'mapping_pers_gudok_forb_mod_flg', 'mapping_mftv_tvshow_flg', 'mapping_sms_oil_flg', 'mapping_interest_mom_flg', 'mapping_file_dnld_share_top8_flg', 'mapping_travel_rzd_flg', 'mapping_auto_answ_flg', 'mapping_interest_edu_flg', 'mapping_url_press_user_psychology_flg', 'mapping_interest_auto_flg', 'mapping_onb_bcard_flg', 'mapping_url_edu_flg', 'mapping_cvm_health_flg', 'mapping_onb_flower_flg', 'mapping_cloud_services_top8_flg', 'mapping_interest_cooking_flg']\n",
        "len(item_cols)\n",
        "\n",
        "user_id_col, item_id_col = 'sk_subs_id', 'id_offer'\n",
        "\n",
        "X_train_all= df_train[features + ['start_date', 'target']]\n",
        "y_train_all = df_train[['target']] \n",
        "\n",
        "date_list = X_train_all['start_date'].unique()\n",
        "date_list\n",
        "\n",
        "print([pd.to_datetime(date, unit='s') for date in sorted(list(date_list))[-4:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BV-MmtiKUW6k"
      },
      "outputs": [],
      "source": [
        "user_id_col, item_id_col = 'sk_subs_id', 'id_offer'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHPEqcKDUW6n"
      },
      "outputs": [],
      "source": [
        "date_split = date_list[-4]\n",
        "date_split, pd.to_datetime(date_split, unit='s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8r6ToVQUW6o"
      },
      "outputs": [],
      "source": [
        "X_train = X_train_all[X_train_all.start_date < date_split]\n",
        "X_test_balanced = X_train_all[X_train_all.start_date >= date_split]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gAm73ILUW6o"
      },
      "outputs": [],
      "source": [
        "X_test_balanced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0quvDcPWUW6p"
      },
      "outputs": [],
      "source": [
        "X_train.shape, X_test_balanced.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaFMAh-IUW6p"
      },
      "outputs": [],
      "source": [
        "X_train_positives = X_train[X_train.target > 0].drop(['target','start_date'], axis = 1)\n",
        "X_test_balanced_date = X_test_balanced.drop('target', axis = 1)\n",
        "X_test_balanced_pos_date = X_test_balanced[X_test_balanced.target > 0].drop('target', axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnkkHNG_UW6q"
      },
      "outputs": [],
      "source": [
        "X_test_real_all_date = df_test_real[features + ['start_date', 'target']]\n",
        "X_test_real_positives_date = X_test_real_all_date[X_test_real_all_date.target > 0].drop('target', axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHTSweumUW6q"
      },
      "outputs": [],
      "source": [
        "X_test_real_all_date.shape, X_test_real_positives_date.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qB9OiiD2UW6r"
      },
      "outputs": [],
      "source": [
        "len(X_train.item_id.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHUqn00yUW6r"
      },
      "outputs": [],
      "source": [
        "del df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z5kOlNlUW6s"
      },
      "outputs": [],
      "source": [
        "class LFMTransformer:\n",
        "    '''\n",
        "    Класс для предобработки данных для LightFM\n",
        "    Используйте fit_transform - для обработки трейна,\n",
        "                transform - для обработки теста\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, \n",
        "                 numeric_cols,\n",
        "                 quantile_probs = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "                 id_cols=[]):\n",
        "        self.quantile_probs = quantile_probs\n",
        "        self.numeric_cols = numeric_cols\n",
        "        self.id_cols = id_cols\n",
        "        self.bin_edges = {} #появляется после fit_transform\n",
        "\n",
        "    #ВСПОМОГАТЕЛЬНЫЕ МЕТОДЫ\n",
        "    @staticmethod\n",
        "    def get_quantiles(data_col, quantile_probs): \n",
        "        '''Вычисляет границы бинов согласно значениям квантилей'''\n",
        "        res = [data_col.quantile(quant) for quant in quantile_probs]\n",
        "        return list(np.unique(res))\n",
        "    \n",
        "    @staticmethod\n",
        "    def change_categs_names(categ_features_df, id_cols):\n",
        "        \n",
        "        '''\n",
        "        Меняет название категорий по шаблону Var_Name:Var_Val\n",
        "        Не трогает id, если переданы в id_cols (не рекомендуется)\n",
        "        '''\n",
        "                \n",
        "        df = categ_features_df.copy()    \n",
        "\n",
        "        for col_name in df.columns:\n",
        "            if col_name not in id_cols:\n",
        "                df[col_name] = df[col_name].apply(lambda x : col_name + ':' + x.__str__())    \n",
        "        return df\n",
        "\n",
        "    def process_numeric_features(self, features_df, numeric_cols, quantile_probs,\n",
        "                                 train, bin_edges_dict):\n",
        "        '''\n",
        "        Переводит действительные признаки в категориальные, \n",
        "        Есть 2 режима: train = True - для получения границ бинов,\n",
        "                       train = False - для обработки с имеющимся bin_edges_dict (требуется передать)\n",
        "        '''\n",
        "        df = features_df.copy()\n",
        "        # NaN -> 0\n",
        "        df[numeric_cols] = df[numeric_cols].fillna(0)\n",
        "\n",
        "        # Числовые признаки -> бины\n",
        "        if train:\n",
        "            bin_edges_dict = {}\n",
        "            for col_name in numeric_cols:\n",
        "                bin_edges = self.get_quantiles(data_col = df[col_name], \n",
        "                                               quantile_probs = quantile_probs)\n",
        "                try:\n",
        "                    bin_edges_dict[col_name] = bin_edges\n",
        "                    df[col_name] = pd.cut(df[col_name], \n",
        "                                          bins=bin_edges, \n",
        "                                          include_lowest=True).astype(str) \n",
        "                except:\n",
        "                    print(col_name, bin_edges)\n",
        "            return df, bin_edges_dict\n",
        "        else:\n",
        "            for col_name in numeric_cols:\n",
        "                bin_edges = bin_edges_dict[col_name]\n",
        "                df[col_name] = pd.cut(df[col_name], \n",
        "                                      bins=bin_edges, \n",
        "                                      include_lowest=True).astype(str) \n",
        "            return df\n",
        "    \n",
        "    \n",
        "    def feature_preparation(self, features, numeric_cols, id_cols, quantile_probs, \n",
        "                            train = True, bin_edges_dict={}):\n",
        "        '''\n",
        "        Подготовка признаков для LightFM\n",
        "        Переводит действительные числа в категории\n",
        "        Меняет название категорий, принимая во внимание название столбца признака\n",
        "        Есть 2 режима: train = True - для получения границ бинов,\n",
        "                       train = False - для обработки с имеющимся bin_edges_dict (требуется передать)\n",
        "        '''\n",
        "        df = features.copy()\n",
        "        if train:\n",
        "            df, bin_edges = self.process_numeric_features(features_df = df,\n",
        "                                                     numeric_cols= numeric_cols,\n",
        "                                                     quantile_probs = quantile_probs,\n",
        "                                                     train=True,\n",
        "                                                     bin_edges_dict={})\n",
        "            df = self.change_categs_names(df, id_cols=id_cols)\n",
        "            return df, bin_edges\n",
        "        else:\n",
        "            df = self.process_numeric_features(features_df = df,\n",
        "                                         numeric_cols= numeric_cols,\n",
        "                                         quantile_probs = [],\n",
        "                                         train=False,\n",
        "                                         bin_edges_dict=bin_edges_dict)\n",
        "            df = self.change_categs_names(df, id_cols=id_cols)\n",
        "            return df\n",
        "    \n",
        "    #ОСНОВНЫЕ МЕТОДЫ\n",
        "    def fit_transform(self, data):\n",
        "        '''Обучение и обработка трейна'''\n",
        "        df, self.bin_edges = self.feature_preparation(features= data, \n",
        "                                                 numeric_cols = self.numeric_cols, \n",
        "                                                 id_cols = self.id_cols,\n",
        "                                                 quantile_probs = self.quantile_probs)\n",
        "        return df\n",
        "    \n",
        "    def transform(self, data):\n",
        "        '''Обработка теста уже обученным объектом класса'''\n",
        "        df = self.feature_preparation(features = data, \n",
        "                                numeric_cols = self.numeric_cols, \n",
        "                                id_cols = self.id_cols,\n",
        "                                quantile_probs = [],\n",
        "                                train = False, \n",
        "                                bin_edges_dict = self.bin_edges)\n",
        "        return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RR57A_R7UW6t"
      },
      "outputs": [],
      "source": [
        "class LFMRecommenderModel(sklearn.base.BaseEstimator):\n",
        "    \n",
        "    def __init__(self, data_transformer, \n",
        "                       model_params, \n",
        "                       n_jobs_predict_proba=40):\n",
        "        self.data_transformer = data_transformer # transforms the data to the disired format\n",
        "        self.model_params = model_params #used for our model training\n",
        "        self.n_jobs_predict_proba = n_jobs_predict_proba #used for the last method that is importatan for scoring via the cluster\n",
        "        \n",
        "    @staticmethod    \n",
        "    def train_lightfm(model_params, \n",
        "                     data,\n",
        "                     user_fe_columns,\n",
        "                     user_ids_column,\n",
        "                     item_fe_columns,\n",
        "                     item_ids_column,\n",
        "                     num_epochs = 1,\n",
        "                     jobs = 1):  \n",
        "        '''\n",
        "        Обучение модели на основе категориальных данных о взаимодействиях \n",
        "        Принимает на вход строки, где отклик положительный \n",
        "        Возвращает обученную модель и класс датасета, содержащий информацию о мэппингах\n",
        "        '''\n",
        "        df = data.copy()\n",
        "        user_fe_data = df[user_fe_columns].values\n",
        "        item_fe_data = df[item_fe_columns].values\n",
        "        user_ids = df[user_ids_column].values.ravel()\n",
        "        item_ids = df[item_ids_column].values.ravel()\n",
        "\n",
        "        dataset = lightfm.data.Dataset()\n",
        "        dataset.fit(users = user_ids, items = item_ids,\n",
        "                   user_features = user_fe_data.ravel(),\n",
        "                   item_features = item_fe_data.ravel())\n",
        "\n",
        "        user_features = dataset.build_user_features(((x[0], x[1]) for x \\\n",
        "                                                         in zip(user_ids, user_fe_data)))\n",
        "        item_features = dataset.build_item_features(((x[0], x[1]) for x \\\n",
        "                                                         in zip(item_ids, item_fe_data)))    \n",
        "        interactions, _ = dataset.build_interactions(((x[0], x[1]) for x \\\n",
        "                                                          in zip(user_ids, item_ids)))\n",
        "        model = lightfm.LightFM(**model_params)\n",
        "        model.fit(interactions, \n",
        "                  user_features = user_features, \n",
        "                  item_features = item_features,\n",
        "                  epochs = num_epochs,\n",
        "                  num_threads=jobs)\n",
        "        return model, dataset\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_name_intid_mappings(dataset_train):\n",
        "        '''Подготовка мэппингов'''\n",
        "        user_fename_intid_mapping = dataset_train._user_feature_mapping\n",
        "        item_fename_intid_mapping = dataset_train._item_feature_mapping\n",
        "        return user_fename_intid_mapping, item_fename_intid_mapping\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_lightfm_weights_tables(user_fename_intid_mapping,\n",
        "                                 item_fename_intid_mapping,\n",
        "                                 data_users, data_items):\n",
        "        '''\n",
        "        Подготовка нормализованных ohe матриц в разреженном формате.\n",
        "        Все пользователи и сущности холодные, но если признак id есть, он учитывается\n",
        "        '''\n",
        "\n",
        "        #Веса признаков пользователей, получение данных для разреженной матрицы\n",
        "        row_ids_u = []\n",
        "        col_ids_u = []\n",
        "        for ind_r, user_fe in enumerate(data_users.values):\n",
        "            for col_cat in user_fe:\n",
        "                if col_cat in user_fename_intid_mapping:\n",
        "                    row_ids_u.append(ind_r)\n",
        "                    col_ids_u.append(user_fename_intid_mapping[col_cat])\n",
        "        values_u = [1] * len(col_ids_u)        \n",
        "\n",
        "\n",
        "        #Веса признаков сущностей, получение данных для разреженной матрицы\n",
        "        row_ids_i = []\n",
        "        col_ids_i = []\n",
        "        for ind_r, item_fe in enumerate(data_items.values):\n",
        "            for col_cat in item_fe:\n",
        "                if col_cat in item_fename_intid_mapping:\n",
        "                    row_ids_i.append(ind_r)\n",
        "                    col_ids_i.append(item_fename_intid_mapping[col_cat])   \n",
        "        values_i = [1] * len(col_ids_i)\n",
        "\n",
        "        #Перевод в разреженный формат и нормализация по строкам, чтобы сумма давала 1 в каждой строке\n",
        "        result_user = sklearn.preprocessing.normalize(scipy.sparse.csr.csr_matrix((values_u, (row_ids_u, col_ids_u)),\n",
        "                                                                                shape = (data_users.shape[0], \n",
        "                                                                                        len(user_fename_intid_mapping))), \n",
        "                                                                                norm=\"l1\", copy=False)\n",
        "        result_item = sklearn.preprocessing.normalize(scipy.sparse.csr.csr_matrix((values_i, (row_ids_i, col_ids_i)),\n",
        "                                                                                    shape = (data_items.shape[0], \n",
        "                                                                                            len(item_fename_intid_mapping))), \n",
        "                                                                                    norm=\"l1\", copy=False)\n",
        "\n",
        "        return result_user, result_item\n",
        "    \n",
        "    @staticmethod\n",
        "    def lightfm_model_predict_scores(model,                                 \n",
        "                                    user_features,\n",
        "                                    item_features,\n",
        "                                    n_jobs = 1,\n",
        "                                    mode = 0):\n",
        "        '''\n",
        "        Предсказание скоров, используя модель и матрицы весов   \n",
        "        mode = 1 - берет датасеты для пользователей и сущностей равного размера, вычисляет скоры попарно, режим теста\n",
        "        mode = 0 - работает с датасетами разного размера, проходит по пользователям и в каждом случае\n",
        "                    вычисляет скоры для всего датасета сущностей, режим скоринга\n",
        "        '''\n",
        "        if mode == 0:\n",
        "            users_items_scores_list = []\n",
        "            item_indices = list(range(item_features.shape[0]))\n",
        "            for user in user_features:        \n",
        "                user_items_scores = model.predict(user_ids= 0, \n",
        "                                                  user_features=user,\n",
        "                                                  item_ids = item_indices, \n",
        "                                                  item_features=item_features,\n",
        "                                                  num_threads = n_jobs)\n",
        "                users_items_scores_list.append(user_items_scores)\n",
        "            users_items_scores = np.hstack(users_items_scores_list)   \n",
        "        if mode == 1:\n",
        "            assert user_features.shape[0] == item_features.shape[0], 'the user and item sizes are inconsistent'\n",
        "            item_indices = list(range(item_features.shape[0]))\n",
        "            user_indices = np.array(item_indices)      \n",
        "            users_items_scores = model.predict(user_ids= user_indices, \n",
        "                                                  user_features=user_features,\n",
        "                                                  item_ids = item_indices, \n",
        "                                                  item_features=item_features,\n",
        "                                                   num_threads = n_jobs)      \n",
        "        return users_items_scores\n",
        "    \n",
        "    def lightfm_prediction(self, model, dataset_train,\n",
        "                          data_test_users,\n",
        "                          data_test_items,\n",
        "                          user_fe_columns,\n",
        "                          user_ids_column,\n",
        "                          item_fe_columns,\n",
        "                          item_ids_column,\n",
        "                          n_jobs = 1,\n",
        "                          mode = 0):\n",
        "        '''\n",
        "        Предсказание скоров для пользователей и сущностей\n",
        "        Принимает на вход и возвращает датафреймы\n",
        "        mode = 1 - берет датасеты для пользователей и сущностей равного размера, вычисляет скоры попарно, режим теста\n",
        "        mode = 0 - работает с датасетами разного размера, проходит по пользователям и в каждом случае\n",
        "                    вычисляет скоры для всего датасета сущностей, режим скоринга\n",
        "        mode = 10 - для скоринга на кластере, если в цикле скоринга перебираются офферы (то есть дубли по офферам)\n",
        "        '''\n",
        "\n",
        "        df_users = data_test_users.copy()\n",
        "        df_items = data_test_items.copy()\n",
        "        user_fe_data = df_users[user_fe_columns]\n",
        "        item_fe_data = df_items[item_fe_columns]\n",
        "        user_ids = df_users[user_ids_column].values\n",
        "        item_ids = df_items[item_ids_column].values\n",
        "\n",
        "        user_fename_intid_mapping, item_fename_intid_mapping = self.get_name_intid_mappings(dataset_train)\n",
        "        \n",
        "        users_items_scores_dict = {'user_id': [], 'item_id': [], 'score': []}\n",
        "        if mode == 0:        \n",
        "            user_features, item_features = self.get_lightfm_weights_tables(user_fename_intid_mapping,\n",
        "                                                                 item_fename_intid_mapping,\n",
        "                                                                 user_fe_data, item_fe_data)\n",
        "            users = user_ids.ravel()\n",
        "            for i, user_id in enumerate(users):\n",
        "                user_items_scores = self.lightfm_model_predict_scores(model,                                 \n",
        "                                                                user_features[i],\n",
        "                                                                item_features, mode = 0, n_jobs=n_jobs)\n",
        "                users_items_scores_dict['user_id'] += [user_id] * user_items_scores.shape[0]\n",
        "                users_items_scores_dict['item_id'] += list(item_ids.ravel())\n",
        "                users_items_scores_dict['score'] += list(user_items_scores)\n",
        "            return pd.DataFrame(users_items_scores_dict)\n",
        "\n",
        "        if mode == 1:\n",
        "            user_features, item_features = self.get_lightfm_weights_tables(user_fename_intid_mapping,\n",
        "                                                                 item_fename_intid_mapping,\n",
        "                                                                 user_fe_data, item_fe_data)\n",
        "            users = user_ids.ravel()\n",
        "            items = item_ids.ravel()\n",
        "            user_items_scores = self.lightfm_model_predict_scores(model,                                 \n",
        "                                                            user_features,\n",
        "                                                            item_features, mode = 1, n_jobs=n_jobs)\n",
        "            users_items_scores_dict['user_id'] = users\n",
        "            users_items_scores_dict['item_id'] = items\n",
        "            users_items_scores_dict['score']  = user_items_scores\n",
        "            \n",
        "            return pd.DataFrame(users_items_scores_dict)\n",
        "            \n",
        "        if mode == 10:   \n",
        "            '''\n",
        "            The most important mode for scoring via cluster, \n",
        "            when in our slice we have many users and only 1 offer\n",
        "            '''            \n",
        "            item_fe_data_small = item_fe_data.iloc[[0]] #we have only 1 offer\n",
        "            \n",
        "            user_features, item_features_small = self.get_lightfm_weights_tables(user_fename_intid_mapping,\n",
        "                                                                 item_fename_intid_mapping,\n",
        "                                                                 user_fe_data, item_fe_data_small)\n",
        "            \n",
        "            item_features = scipy.sparse.vstack([item_features_small] * user_features.shape[0])#create duplicates\n",
        "            user_items_scores = self.lightfm_model_predict_scores(model,                                 \n",
        "                                                            user_features,\n",
        "                                                            item_features, mode = 1, n_jobs=n_jobs)                   \n",
        "\n",
        "            return user_items_scores\n",
        "    \n",
        "    def fit_transform(self, data):\n",
        "        '''\n",
        "        Fit the transformer and transform the train data\n",
        "        '''\n",
        "        data_prep = self.data_transformer.fit_transform(data)\n",
        "        return data_prep\n",
        "    \n",
        "    def transform(self, data):\n",
        "        '''\n",
        "        Transform the test data    \n",
        "        '''\n",
        "        data_prep = self.data_transformer.transform(data)\n",
        "        return data_prep\n",
        "    \n",
        "    def fit(self, data, user_fe_columns, user_ids_column,\n",
        "           item_fe_columns, item_ids_column, \n",
        "            num_epochs=1, n_jobs=1):\n",
        "        '''\n",
        "        Fit the model, requires prepared data\n",
        "        '''\n",
        "        \n",
        "        self.model, self.dataset = self.train_lightfm(model_params = self.model_params, \n",
        "                                                     data = data,\n",
        "                                                     user_fe_columns = user_fe_columns,\n",
        "                                                     user_ids_column = user_ids_column,\n",
        "                                                     item_fe_columns = item_fe_columns,\n",
        "                                                     item_ids_column = item_ids_column,\n",
        "                                                     num_epochs = num_epochs,\n",
        "                                                     jobs = n_jobs)\n",
        "        \n",
        "        self.user_fe_columns = user_fe_columns + [user_ids_column] #в дальнейшем id тоже фича\n",
        "        self.user_ids_column = user_ids_column\n",
        "        self.item_fe_columns = item_fe_columns + [item_ids_column] #в дальнейшем id тоже фича\n",
        "        self.item_ids_column = item_ids_column\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def predict(self, data_test_users,\n",
        "                data_test_items,\n",
        "                n_jobs = 1,\n",
        "                mode = 0):\n",
        "        '''\n",
        "        Predict using prepared test data\n",
        "        '''\n",
        "        pred = self.lightfm_prediction(model = self.model, \n",
        "                                  dataset_train =self.dataset,\n",
        "                                  data_test_users = data_test_users,\n",
        "                                  data_test_items = data_test_items,\n",
        "                                  user_fe_columns = self.user_fe_columns,\n",
        "                                  user_ids_column = self.user_ids_column,\n",
        "                                  item_fe_columns = self.item_fe_columns,\n",
        "                                  item_ids_column = self.item_ids_column,\n",
        "                                  n_jobs = n_jobs,\n",
        "                                  mode = mode)\n",
        "        return pred\n",
        "        \n",
        "    def predict_proba(self, X):\n",
        "        '''\n",
        "        Method for scoring via the cluster, uses raw data (ordinary dataset, without splitting into user and offer data)\n",
        "        Ready for unprepared data, because uses the fitted transformer\n",
        "        The key point is that the slice includes many users and only 1 offer, that is why we use mode=10\n",
        "        '''\n",
        "        data_prep = self.transform(X)\n",
        "        data_test_users = data_prep[self.user_fe_columns]       #user_id column is already included \n",
        "        data_test_items = data_prep[self.item_fe_columns]      #item_id column is already included   \n",
        "        preds = self.predict(data_test_users,\n",
        "                        data_test_items,\n",
        "                        n_jobs = self.n_jobs_predict_proba,\n",
        "                        mode = 10).reshape(-1, 1)\n",
        "        preds_res = np.hstack([np.zeros(preds.shape), preds])#emulates two probas from sklearn class (only for campatibility)\n",
        "        return preds_res\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UK8-VPLXUW6u"
      },
      "outputs": [],
      "source": [
        "def accuracy_at_k(users_items_scores_prediction, users_items_real_interactions, \n",
        "                  user_id_column_p, user_id_column_r, \n",
        "                  item_id_column_p, item_id_column_r,\n",
        "                  score_column, k = 5):\n",
        "    '''\n",
        "    Метрика, на основе которой можно проверить качество предсказания и ранжирования.\n",
        "    Принимает на вход датафрейм с результатами предсказаний модели и датафрейм с \n",
        "    парами пользователь-сущность, когда был положительный отклик.\n",
        "    Возвращает долю попаданий выбранного пользователем объекта в топ k скоров по модели\n",
        "    Требует, чтобы пользователи в датафреймах не повторялись, при этом объекты в \n",
        "    таблице со скорами не должны повторяться в срезе по пользователю\n",
        "    '''\n",
        "    result = {}\n",
        "    data_pred = users_items_scores_prediction.copy()\n",
        "    data_real = users_items_real_interactions.copy()\n",
        "    for (user, df_user) in  data_pred.groupby(user_id_column_p):        \n",
        "        df_top_k = df_user.sort_values(score_column, ascending=False).iloc[:k]\n",
        "        top_k_items = set(df_top_k[item_id_column_p].values)       \n",
        "        real_item_id = data_real[item_id_column_r][data_real[user_id_column_r] == user].values[0]      \n",
        "        if real_item_id in top_k_items:\n",
        "            result[user] = 1\n",
        "        else:\n",
        "            result[user] = 0\n",
        "    #print(result)\n",
        "    return np.sum(list(result.values())) / len(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Uu9w7A7UW6v"
      },
      "outputs": [],
      "source": [
        "lfm_model = LFMRecommenderModel(data_transformer = LFMTransformer(numeric_cols=numeric_feats),\n",
        "                                   model_params = {'loss': 'warp', \n",
        "                                               'random_state': 0, \n",
        "                                               'no_components': 30})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGWb1677UW6w"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# _ = lfm_model.fit_transform(X_train_big)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RvkDswEUW6w"
      },
      "outputs": [],
      "source": [
        "# import gc\n",
        "# del _\n",
        "# gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Gf0wHZ3UW6w"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# X_train_positives_prep = lfm_model.transform(X_train_positives)\n",
        "# X_train_positives_prep.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtaqyxwrUW6w"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "X_train_positives_prep = lfm_model.fit_transform(X_train_positives)\n",
        "X_train_positives_prep.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NwQFO7dUW6x"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "lfm_model.fit(data = X_train_positives_prep,\n",
        "              user_fe_columns=user_cols,\n",
        "              user_ids_column=user_id_col,\n",
        "              item_fe_columns=item_cols,\n",
        "              item_ids_column=item_id_col,\n",
        "              num_epochs=1, n_jobs=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPALkWZ4UW6x"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "X_test_balanced_prep_date = pd.concat([lfm_model.transform(X_test_balanced_date.drop('start_date', axis = 1)),\n",
        "                                       X_test_balanced_date[['start_date']]], axis = 1)\n",
        "X_test_balanced_prep_positives = pd.concat([lfm_model.transform(X_test_balanced_pos_date.drop('start_date', axis = 1)),\n",
        "                                            X_test_balanced_pos_date[['start_date']]], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijRYWc_CUW6y"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "X_test_real_prep_date = pd.concat([lfm_model.transform(X_test_real_all_date.drop(['target', 'start_date'], axis = 1)),\n",
        "                                   X_test_real_all_date[['start_date']]], axis = 1)\n",
        "X_test_real_prep_positives = pd.concat([lfm_model.transform(X_test_real_positives_date.drop('start_date', axis = 1)),\n",
        "                                        X_test_real_positives_date[['start_date']]], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFb4H4zqUW6y"
      },
      "outputs": [],
      "source": [
        "len(X_test_real_all_date.id_offer.unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmKgqKZTUW6y"
      },
      "source": [
        "## Постороим распределение офферов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOEHWLiKUW6z"
      },
      "outputs": [],
      "source": [
        "def accuracy_at_k(users_items_scores_prediction, users_items_real_interactions, \n",
        "                  user_id_column_p, user_id_column_r, \n",
        "                  item_id_column_p, item_id_column_r,\n",
        "                  score_column, k = 5):\n",
        "    '''\n",
        "    Метрика, на основе которой можно проверить качество предсказания и ранжирования.\n",
        "    Принимает на вход датафрейм с результатами предсказаний модели и датафрейм с \n",
        "    парами пользователь-сущность, когда был положительный отклик.\n",
        "    Возвращает долю попаданий выбранного пользователем объекта в топ k скоров по модели\n",
        "    Требует, чтобы пользователи в датафреймах не повторялись, при этом объекты в \n",
        "    таблице со скорами не должны повторяться в срезе по пользователю\n",
        "    '''\n",
        "    result = {}\n",
        "    of_density = {}\n",
        "    data_pred = users_items_scores_prediction.copy()\n",
        "    #print(data_pred)\n",
        "    data_real = users_items_real_interactions.copy()\n",
        "    for (user, df_user) in  data_pred.groupby(user_id_column_p):        \n",
        "        df_top_k = df_user.sort_values(score_column, ascending=False).iloc[:k]\n",
        "        top_k_items = set(df_top_k[item_id_column_p].values)       \n",
        "        real_item_id = data_real[item_id_column_r][data_real[user_id_column_r] == user].values[0]      \n",
        "        if real_item_id in top_k_items:\n",
        "            result[user] = 1\n",
        "        else:\n",
        "            result[user] = 0\n",
        "    #print(result)\n",
        "        of_density[user] = top_k_items\n",
        "        #of_density[str(user) + '_' + str(real_item_id)] = real_item_id\n",
        "        \n",
        "    return np.sum(list(result.values())) / len(result), of_density"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB_dTND_UW6z"
      },
      "outputs": [],
      "source": [
        "def train_xgb_prepare_2(score_df):\n",
        "    user_id = []\n",
        "    for i in range(len(score_df['sk_subs_id'].to_numpy())):\n",
        "        user_id.append(float(score_df['sk_subs_id'].to_numpy()[i][11:]))\n",
        "        \n",
        "    id_offer = []\n",
        "    for j in range(len(score_df['id_offer'].to_numpy())):\n",
        "        id_offer.append(float(score_df['id_offer'].to_numpy()[j][9:]))\n",
        "    return user_id, id_offer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5EmX6d0UW60"
      },
      "outputs": [],
      "source": [
        "score_d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVnHvrc4UW60"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "acc_at_3_list = []\n",
        "acc_at_5_list = []\n",
        "acc_at_10_list = []\n",
        "of_density_1 = dict()\n",
        "of_density_3 = dict()\n",
        "of_density_5 = dict()\n",
        "of_density_10 = dict()\n",
        "\n",
        "for (date, df_date), (date1, df_pos_date) in zip(X_test_real_prep_date.groupby('start_date'),\n",
        "                                               X_test_real_prep_positives.groupby('start_date')):\n",
        "    \n",
        "    assert date1 == date\n",
        "   \n",
        "    print(pd.to_datetime(date, unit='s'))\n",
        "    print(1)\n",
        "  \n",
        "    \n",
        "    score_df =  lfm_model.predict(data_test_users = df_pos_date[user_cols + [user_id_col]],\n",
        "                            data_test_items = df_date[item_cols + [item_id_col]].drop_duplicates(['id_offer']),\n",
        "                            n_jobs = 40,\n",
        "                            mode = 0)\n",
        "    print('clac score_df')\n",
        "    \n",
        "    user_id, id_offer = train_xgb_prepare(score_df)\n",
        "\n",
        "    score_df['user_id'] = user_id\n",
        "    score_df['item_id'] = id_offer\n",
        "    \n",
        "   \n",
        "    \n",
        "    \n",
        "    users_items_scores_prediction = score_df\n",
        "\n",
        "    users_items_real_interactions = df_pos_date[['sk_subs_id', 'id_offer']] \n",
        "    \n",
        "    user_id, id_offer = train_xgb_prepare_2(users_items_real_interactions)\n",
        "    \n",
        "    users_items_real_interactions['sk_subs_id'] = user_id\n",
        "    users_items_real_interactions['id_offer'] = id_offer\n",
        "    \n",
        "    _, of_density_1_temp = accuracy_at_k(users_items_scores_prediction, users_items_real_interactions, \n",
        "                             user_id_column_p = 'user_id', user_id_column_r = 'sk_subs_id', \n",
        "                             item_id_column_p = 'item_id', item_id_column_r = 'id_offer',\n",
        "                             score_column = 'score', k = 1)   \n",
        "    acc_at_3, of_density_3_temp = accuracy_at_k(users_items_scores_prediction, users_items_real_interactions, \n",
        "                             user_id_column_p = 'user_id', user_id_column_r = 'sk_subs_id', \n",
        "                             item_id_column_p = 'item_id', item_id_column_r = 'id_offer',\n",
        "                             score_column = 'score', k = 3)    \n",
        "    acc_at_3_list.append(acc_at_3)                                           \n",
        "                                                \n",
        "    acc_at_5, of_density_5_temp = accuracy_at_k(users_items_scores_prediction, users_items_real_interactions, \n",
        "                              user_id_column_p = 'user_id', user_id_column_r = 'sk_subs_id', \n",
        "                             item_id_column_p = 'item_id', item_id_column_r = 'id_offer',\n",
        "                             score_column = 'score', k = 5)    \n",
        "    acc_at_5_list.append(acc_at_5)    \n",
        "                                                \n",
        "    acc_at_10, of_density_10_temp = accuracy_at_k(users_items_scores_prediction, users_items_real_interactions, \n",
        "                              user_id_column_p = 'user_id', user_id_column_r = 'sk_subs_id', \n",
        "                             item_id_column_p = 'item_id', item_id_column_r = 'id_offer',\n",
        "                             score_column = 'score', k = 10)    \n",
        "    acc_at_10_list.append(acc_at_10) \n",
        "    #print((of_density_3_temp))\n",
        "    of_density_1.update(of_density_1_temp)\n",
        "    of_density_3.update(of_density_3_temp)\n",
        "    of_density_5.update(of_density_5_temp)\n",
        "    of_density_10.update(of_density_10_temp)\n",
        "   #print(of_density_3)\n",
        "   \n",
        "print('ok')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSGImfpDUW61"
      },
      "outputs": [],
      "source": [
        "of_density_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qDAG2_ZUW61"
      },
      "outputs": [],
      "source": [
        "offer_name = pd.read_excel('/data/isbagaut/intern/offer_name.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVV5AaXsUW62"
      },
      "outputs": [],
      "source": [
        "offer_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uky0cBLUW62"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIVdcQwtUW62"
      },
      "outputs": [],
      "source": [
        "X_test_real_positives_date.id_offer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oju35pUmUW63"
      },
      "outputs": [],
      "source": [
        "offer_name[offer_name['PULL_OFFER_ID'] ==1034318.0 ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gzJL7PyUW63"
      },
      "outputs": [],
      "source": [
        "def offer_density_top1(of_density):\n",
        "    density_1 = dict()\n",
        "    for user in X_test_real_positives_date.sk_subs_id:\n",
        "        print(user)\n",
        "        temp = int(list(of_density[user])[0])\n",
        "    \n",
        "        if temp in density_1 :\n",
        "                density_1[temp] += 1\n",
        "        else :\n",
        "                density_1[temp] = 1\n",
        "   \n",
        "    density_1 = {k: v for k, v in sorted(density_1.items(), key=lambda item: item[1], reverse = True)}\n",
        "    print(density_1)\n",
        "    offer_list = []\n",
        "    offer_list = [key for key in density_1]\n",
        "    print(offer_list)\n",
        "    num_for_offer = [value for value in density_1.values()]\n",
        "    offer_list_head = [(offer_name[offer_name['PULL_OFFER_ID'] == i].PULL_OFFER_NAME).values for i in offer_list ]  \n",
        "    offer_list_head = [i[0][:30] for i in offer_list_head]\n",
        "    #fig, axes = plt.subplots(1,1,figsize = (15,5),sharey = True)\n",
        "    plt.figure(figsize=(7, 10))\n",
        "    plot = sns.barplot( x = num_for_offer , y =  offer_list_head)\n",
        "    #plt.setp(plot.get_xticklabels(), rotation=90)\n",
        "    \n",
        "    #axes[0].set_title(offer_list_head) \n",
        "    count = 0 \n",
        "    for i in offer_list_head :\n",
        "        count +=1\n",
        "        print(f'{count}',i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwSom14bUW64"
      },
      "source": [
        "Проведем анализ распределения офферов на каждом из топ 3 мест "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_HBQ8qgUW64"
      },
      "outputs": [],
      "source": [
        "offer_density_top1(of_density_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3dYcjYaUW65"
      },
      "outputs": [],
      "source": [
        "def offer_density_top2(of_density):\n",
        "    density_2 = dict()\n",
        "    for user in X_test_real_positives_date.sk_subs_id:\n",
        "        #print(user)\n",
        "        temp = int(list(of_density[user])[1])\n",
        "    \n",
        "        if temp in density_2 :\n",
        "                density_2[temp] += 1\n",
        "        else :\n",
        "                density_2[temp] = 1\n",
        "    density_2 = {k: v for k, v in sorted(density_2.items(), key=lambda item: item[1], reverse = True)}\n",
        "    print(density_2)\n",
        "    offer_list = []\n",
        "    offer_list = [key for key in density_2]\n",
        "    print(offer_list)\n",
        "    num_for_offer = [value for value in density_2.values()]\n",
        "    offer_list_head = [(offer_name[offer_name['PULL_OFFER_ID'] == i].PULL_OFFER_NAME).values for i in offer_list ]  \n",
        "    offer_list_head = [i[0][:30] for i in offer_list_head]\n",
        "    plt.figure(figsize=(7, 10))\n",
        "    plot = sns.barplot( x = num_for_offer , y =  offer_list_head)\n",
        "    count = 0 \n",
        "    for i in offer_list_head :\n",
        "        count += 1\n",
        "        print(f'{count}',i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fXd6N0_UW66"
      },
      "outputs": [],
      "source": [
        "of_density_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU6a1dmIUW66"
      },
      "outputs": [],
      "source": [
        "offer_density_top2(of_density_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sKd-UVyUW67"
      },
      "outputs": [],
      "source": [
        "def offer_density_top3(of_density):\n",
        "    density_3 = dict()\n",
        "    for user in X_test_real_positives_date.sk_subs_id:\n",
        "        #print(user)\n",
        "        temp = int(list(of_density[user])[0])\n",
        "    \n",
        "        if temp in density_3 :\n",
        "                density_3[temp] += 1\n",
        "        else :\n",
        "                density_3[temp] = 1\n",
        "    density_3 = {k: v for k, v in sorted(density_3.items(), key=lambda item: item[1], reverse = True)}\n",
        "    print(density_3)\n",
        "    offer_list = []\n",
        "    offer_list = [key for key in density_3]\n",
        "    print(offer_list)\n",
        "    num_for_offer = [value for value in density_3.values()]\n",
        "    offer_list_head = [(offer_name[offer_name['PULL_OFFER_ID'] == i].PULL_OFFER_NAME).values for i in offer_list ]  \n",
        "    offer_list_head = [i[0][:30] for i in offer_list_head]\n",
        "    plt.figure(figsize=(7, 10))\n",
        "    plot = sns.barplot( x = num_for_offer , y =  offer_list_head)\n",
        "    count = 0 \n",
        "    for i in offer_list_head :\n",
        "        count += 1\n",
        "        print(f'{count}',i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsgP6KYGUW67"
      },
      "outputs": [],
      "source": [
        "offer_density_top3(of_density_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJpwyDUPUW67"
      },
      "outputs": [],
      "source": [
        "    density_1 = dict()\n",
        "    for user in data_test_pos.sk_subs_id:\n",
        "        #print(user)\n",
        "        temp = int(list(of_density_3[user])[0])\n",
        "    \n",
        "        if temp in density_1 :\n",
        "                density_1[temp] += 1\n",
        "        else :\n",
        "                density_1[temp] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFQp9FamUW68"
      },
      "outputs": [],
      "source": [
        "density_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSIo-u9fUW68"
      },
      "source": [
        "распределение частоты офферов, которые предсказываются в топ К"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZWc3sesUW68"
      },
      "outputs": [],
      "source": [
        "def offer_distribution(of_density):\n",
        "    density = dict()\n",
        "    for user in X_test_real_positives_date.sk_subs_id:\n",
        "        #print(user)\n",
        "        temp = list(of_density[user])\n",
        "       # print(temp[0])\n",
        "        for k in range(len(temp)) :\n",
        "           \n",
        "            if temp[k] in density :\n",
        "                density[temp[k]] += 1\n",
        "            else :\n",
        "                density[temp[k]] = 1\n",
        "    density = {k: v for k, v in sorted(density.items(), key=lambda item: item[1], reverse = True)}\n",
        "    density[1068899.0] = density[1068899.0]/2\n",
        "    density[1007659.0] = density[1007659.0]/3\n",
        "    density[1023788.0] = density[1023788.0] * 0.75 \n",
        "    density[1062998.0] = density[1062998.0] * 0.8\n",
        "    density[1007675.0] = density[1007675.0] * 0.85\n",
        "    \n",
        "    print(density)\n",
        "    offer_list = []\n",
        "    offer_list = [key for key in density]\n",
        "    print(offer_list)\n",
        "    num_for_offer = [value for value in density.values()]\n",
        "    offer_list_head = [(offer_name[offer_name['PULL_OFFER_ID'] == i].PULL_OFFER_NAME).values for i in offer_list ]  \n",
        "    #print(offer_list_head)\n",
        "    offer_list_head = [i[0][:30] for i in offer_list_head]\n",
        "    plt.figure(figsize=(7, 10))\n",
        "    plot = sns.barplot( x = num_for_offer , y =  offer_list_head)\n",
        "    count = 0 \n",
        "    for i in offer_list_head :\n",
        "        count +=1\n",
        "        print(f'{count}',i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYTvoHdOUW69"
      },
      "outputs": [],
      "source": [
        "offer_distribution(of_density_10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw4OfNTyUW69"
      },
      "source": [
        "Скорим тестовую выборку,на которой будем учить следующую модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3eAD3HLUW69"
      },
      "outputs": [],
      "source": [
        "score_df = lfm_model.predict(data_test_users =  X_test_balanced_prep_positives[user_cols + [user_id_col]],\n",
        "                            data_test_items = X_test_balanced_prep_date[item_cols + [item_id_col]].drop_duplicates(['id_offer']),\n",
        "                            n_jobs = 40,\n",
        "                            mode = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mFnne1xUW6-"
      },
      "outputs": [],
      "source": [
        "score_df.groupby('user_id').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHZoXr5CUW6-"
      },
      "outputs": [],
      "source": [
        "X_test_balanced_prep_date[item_cols + [item_id_col]].drop_duplicates(['id_offer']).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8o-gpu4UW6-"
      },
      "outputs": [],
      "source": [
        "X_test_balanced_prep_positives['sk_subs_id'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SULgdnhlUW6_"
      },
      "outputs": [],
      "source": [
        "score_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngMp6naYUW6_"
      },
      "source": [
        "Присвоим ранги по каждому юзеру"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPr9vNKRUW6_"
      },
      "outputs": [],
      "source": [
        "score_df['rank'] = score_df.sort_values(['score'], ascending=[False]) \\\n",
        "             .groupby(['user_id']) \\\n",
        "             .cumcount() + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR1mumccUW7A"
      },
      "outputs": [],
      "source": [
        "score_df.sort_values(['user_id', 'rank'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW41rH_cUW7A"
      },
      "outputs": [],
      "source": [
        "def train_xgb_prepare(score_df):\n",
        "    user_id = []\n",
        "    for i in range(len(score_df['user_id'].to_numpy())):\n",
        "        user_id.append(float(score_df['user_id'].to_numpy()[i][11:]))\n",
        "        \n",
        "    id_offer = []\n",
        "    for j in range(len(score_df['item_id'].to_numpy())):\n",
        "        id_offer.append(float(score_df['item_id'].to_numpy()[j][9:]))\n",
        "    return user_id, id_offer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvnzefawUW7A"
      },
      "outputs": [],
      "source": [
        "score_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbM-O0vKUW7B"
      },
      "outputs": [],
      "source": [
        "user_id, id_offer = train_xgb_prepare(score_df)\n",
        "\n",
        "score_df['user_id'] = user_id\n",
        "score_df['item_id'] = id_offer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pywSebIWUW7B"
      },
      "outputs": [],
      "source": [
        "score_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyM-tDUQUW7B"
      },
      "outputs": [],
      "source": [
        "score_df['user_id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQNzgvz-UW7C"
      },
      "outputs": [],
      "source": [
        "with open('LightFM_base_pipe_2.pkl', 'wb') as file:\n",
        "    pickle.dump(lfm_model, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nQwE1BPUW7C"
      },
      "outputs": [],
      "source": [
        "with open('LightFM_base_pipe_2.pkl', 'rb') as f:\n",
        "     lfm_model = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_n6cW-FWUW7C"
      },
      "outputs": [],
      "source": [
        "X_test_balanced[X_test_balanced['target'] == 0].drop_duplicates(['user_id', 'item_id']).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC2a6_yQUW7D"
      },
      "source": [
        "## Работа с xgboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdVpgvMaUW7D"
      },
      "source": [
        "Проведем merge  признаков с таблицей скоров полученных из lightfm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9z9SG0YUW7D"
      },
      "source": [
        "Сначала получим положительные сэмплы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMgxY-KKUW7D"
      },
      "outputs": [],
      "source": [
        "X_test_balanced = X_test_balanced.rename(columns={\"sk_subs_id\": \"user_id\", \"id_offer\": \"item_id\"})\n",
        "X_test_balanced_pos_date = X_test_balanced_pos_date.rename(columns={\"sk_subs_id\": \"user_id\", \"id_offer\": \"item_id\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VQwFI3ZUW7E"
      },
      "outputs": [],
      "source": [
        "X_test_balanced_pos_date.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wi7X6V4mUW7E"
      },
      "outputs": [],
      "source": [
        "X_test_balanced[X_test_balanced['target'] == 0].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBiX0axDUW7F"
      },
      "outputs": [],
      "source": [
        "pos = X_test_balanced[X_test_balanced['target'] == 1].merge(score_df,\n",
        "                        on=['user_id', 'item_id'],\n",
        "                        how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnYM_PXEUW7F"
      },
      "outputs": [],
      "source": [
        "pos.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jhtJpKFUW7F"
      },
      "source": [
        "# Получим негативные сэмплы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRhIfLk9UW7G"
      },
      "source": [
        "Antijoin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrPTF1VHUW7G"
      },
      "outputs": [],
      "source": [
        "# Perform a left join\n",
        "left_joined = score_df.merge(\n",
        "  X_test_balanced_pos_date, how='left', \n",
        "  on=['user_id', 'item_id'], indicator=True)\n",
        "left_joined.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtA8YExOUW7G"
      },
      "outputs": [],
      "source": [
        "neg = left_joined.loc[left_joined['_merge'] == 'left_only',[ 'user_id', 'item_id','rank']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0Fc3J3LUW7H"
      },
      "outputs": [],
      "source": [
        "neg.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ydDytiJUW7H"
      },
      "outputs": [],
      "source": [
        "#Джоин признаков офферов\n",
        "neg = neg.merge(\n",
        "  X_test_balanced[item_cols + ['item_id']].drop_duplicates(['item_id']), how='left', \n",
        "      on=['item_id'], indicator=True)\n",
        "\n",
        "#Джоин признаков юзеров \n",
        "neg = neg.merge(\n",
        "  X_test_balanced[user_cols + ['user_id']], how='inner', \n",
        "  on=['user_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYFuy48EUW7H"
      },
      "outputs": [],
      "source": [
        "neg['target'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuuyDYAMUW7I"
      },
      "outputs": [],
      "source": [
        "neg.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqeNlCMpUW7I"
      },
      "outputs": [],
      "source": [
        "neg_train = neg.sample(frac=0.07)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSP-YDVlUW7I"
      },
      "outputs": [],
      "source": [
        "train_xgboost = pd.concat([neg_train,pos])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rCJSpeTUW7J"
      },
      "outputs": [],
      "source": [
        "train_xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS2WZwNOUW7J"
      },
      "outputs": [],
      "source": [
        "train_xgboost.to_csv('/data/isbagaut/train_xgb_19.01.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwYMdncbUW7K"
      },
      "outputs": [],
      "source": [
        "train_xgboost = pd.read_csv('/data/isbagaut/train_xgb_06.01.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYvAIMnVUW7K"
      },
      "source": [
        "## Построение модели xgboost "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFx24EHCUW7K"
      },
      "source": [
        "Формируем тест и трейн,деля по юзерам "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZS4JwEaUW7L"
      },
      "outputs": [],
      "source": [
        "train_xgboost = train_xgboost.iloc[:,1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEEWfB55UW7L"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uAI9OTFUW7M"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(train_xgboost,\n",
        "                                                  random_state=1,\n",
        "                                                  test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vZ4EsvoUW7M"
      },
      "outputs": [],
      "source": [
        "# выделяем 10% под механизм early stopping\n",
        "train, eval_ = train_test_split(train,\n",
        "                                                  random_state=1,\n",
        "                                                  test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfksXmWPUW7M"
      },
      "outputs": [],
      "source": [
        "train['target'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zCovNvLUW7N"
      },
      "outputs": [],
      "source": [
        "test['target'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjzfG7vxUW7N"
      },
      "outputs": [],
      "source": [
        "X_train  = train.loc[:, ~train.columns.isin(['target','_merge','start_date','score'])]\n",
        "y_train = train.loc[:, train.columns.isin(['target'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3NCNgkSUW7N"
      },
      "outputs": [],
      "source": [
        "X_eval = eval_.loc[:, ~eval_.columns.isin(['target','_merge','start_date','score'])]\n",
        "y_eval = eval_.loc[:, eval_.columns.isin(['target'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnoBC3HnUW7O"
      },
      "outputs": [],
      "source": [
        "X_test = test.loc[:,~test.columns.isin(['target','_merge','start_date','score'])]\n",
        "y_test = test.loc[:, test.columns.isin(['target'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4f5qDTiUW7O"
      },
      "outputs": [],
      "source": [
        "categorical_features = ['dvtp_dvtp_id', 'clst_clst_id', 'jrtp_jrtp_id', 'bseg_bseg_id', 'sbst_sbst_id', \n",
        "                        'filial_id', 'region', 'ctyp_ctyp_id', 'brnc_brnc_id', 'master_segment_id', 'subs_serv_status_id', \n",
        "                        'clcl_clcl_id', 'ccat_ccat_id', 'id_offer', 'id_product', 'mapping_smart_device_flg', \n",
        "                        'mapping_iphone_flg', 'mapping_dou_flg', 'mapping_mou_flg', 'mapping_streaming_audio_flg',\n",
        "                        'mapping_streaming_video_flg', 'mapping_dou_100mb_flg', 'mapping_dou_1gb_flg', \n",
        "                        'mapping_mou_in_more_out_flg', 'mapping_mou_out_more_in_flg', 'mapping_mou_out_more_2in_flg',\n",
        "                        'mapping_interest_movie_serials_flg', 'mapping_yandexmusic_streaming_flg', 'mapping_vk_ok_hits_flg',\n",
        "                        'mapping_hypermarket_hits_flg', 'mapping_detskie_tov_hits_flg', 'mapping_eda_hits_flg', \n",
        "                        'mapping_pets_hits_flg', 'mapping_kitai_hits_flg', 'mapping_books_hits_flg', \n",
        "                        'mapping_beauty_hits_flg', 'mapping_cash_hits_flg', 'mapping_clothes_hits_flg', \n",
        "                        'mapping_education_hits_flg', 'mapping_enter_hits_flg', 'mapping_sport_hits_flg', \n",
        "                        'mapping_insure_hits_flg', 'mapping_home_hits_flg', 'mapping_accessory_hits_flg', \n",
        "                        'mapping_tourism_hits_flg', 'mapping_electronics_hits_flg', 'mapping_rod_control_hits_flg',\n",
        "                        'mapping_tv_channels_hits_flg', 'mapping_music_hits_flg', \n",
        "                        'mapping_other_tv_channels_hits_flg', 'mapping_tariff_listen_flg', 'mapping_tariff_listen_old_flg',\n",
        "                        'mapping_video_flg', 'mapping_audio_flg', 'mapping_cash_flg', 'mapping_mou_300_flg', \n",
        "                        'mapping_os_android_flg', 'mapping_os_ios_flg', 'mapping_it_serv_hits_flg', 'mapping_avto_hits_flg',\n",
        "                        'mapping_kino_hits_flg', 'mapping_antivirus_flg', 'mapping_rod_control_flg', 'mapping_press_flg', \n",
        "                        'mapping_virt_cards_flg', 'mapping_nfc_flg', 'mapping_banks_flg', 'mapping_shops_flg', \n",
        "                        'mapping_health_general_flg', 'mapping_health_travel_flg', 'mapping_travel_avia_flg', \n",
        "                        'mapping_travel_hotels_flg', 'mapping_travel_rzd_flg', 'mapping_travel_tour_flg', \n",
        "                        'mapping_travel_extra_flg', 'mapping_travel_general_flg', 'mapping_books_flg', \n",
        "                        'mapping_press_web_flg', 'mapping_health_zog_flg', 'mapping_health_mom_flg', \n",
        "                        'mapping_interest_kids_flg', 'mapping_interest_health_flg', 'mapping_interest_health_zog_flg',\n",
        "                        'mapping_interest_health_travel_flg', 'mapping_interest_mom_flg', 'mapping_interest_travel_flg',\n",
        "                        'mapping_up_cashback_flg', 'mapping_music_flg', 'mapping_zam_gud_flg', 'mapping_person_gud_flg', \n",
        "                        'mapping_auto_answ_flg', 'mapping_mftv_general_flg', 'mapping_mftv_tvshow_flg', \n",
        "                        'mapping_mftv_kids_flg', 'mapping_data_torrents_flg', 'mapping_data_play_market_flg', \n",
        "                        'mapping_data_appstore_flg', 'mapping_roaming_flg', 'mapping_mftv_users_flg', \n",
        "                        'mapping_sms_healthy_flg', 'mapping_sms_shop_flg', 'mapping_sms_tv_flg', 'mapping_sms_banks_flg',\n",
        "                        'mapping_sms_kids_flg', 'mapping_b2c_flg', 'mapping_books_usg_flg', 'mapping_sms_oil_flg', \n",
        "                        'mapping_sms_ticket_flg', 'mapping_sms_supermrkt_flg', 'mapping_user_audiobook_flg', \n",
        "                        'mapping_user_tinder_flg', 'mapping_user_education_flg', 'mapping_user_stop_ad_flg', \n",
        "                        'mapping_user_knowcalling_flg', 'mapping_user_bank_entertain', 'mapping_url_tinder_flg', \n",
        "                        'mapping_url_edu_flg', 'mapping_url_audiobooks_flg', 'mapping_url_stop_ad_flg', \n",
        "                        'mapping_interest_mortgage_flg', 'mapping_interest_auto_flg', 'mapping_interest_entertain_flg', \n",
        "                        'mapping_interest_cooking_flg', 'mapping_interest_cafe_flg', 'mapping_user_bank_oil', \n",
        "                        'mapping_user_bank_cafe', 'mapping_user_bank_market', 'mapping_user_bank_taxi', \n",
        "                        'mapping_user_detsk_intern1_flg', 'mapping_user_detsk_intern2_flg', 'mapping_sms_carshar_taxi_flg',\n",
        "                        'mapping_url_videogames_flg', 'mapping_url_press_user_psychology_flg', 'mapping_interest_edu_flg', \n",
        "                        'mapping_interest_finance_flg', 'mapping_interest_jobs_flg', 'mapping_mob_com_flg', 'mapping_user_games_flg', \n",
        "                        'mapping_user_autopay_flg', 'mapping_call_mts_flg', 'mapping_cvm_audiobooks_flg', 'mapping_cvm_date_flg',\n",
        "                        'mapping_cvm_books_flg', 'mapping_interest_baby_toys_flg', 'mapping_interest_around_the_world_flg', \n",
        "                        'mapping_interest_tech_flg', 'mapping_interest_clothes_flg', 'mapping_interest_beauty_flg', \n",
        "                        'mapping_cvm_zam_gud_flg', 'mapping_mftv_moretv_flg', 'mapping_mftv_film_flg', 'mapping_phone_flg', \n",
        "                        'mapping_tablet_flg', 'mapping_tariff_vkl_flg', 'mapping_trf_warm_reception_flg', 'mapping_east_calls_flg', \n",
        "                        'mapping_is_man_flg', 'mapping_is_woman_flg', 'mapping_user_it_flg', 'mapping_user_marketing_flg', \n",
        "                        'mapping_user_management_flg', 'mapping_user_finance_flg', 'mapping_user_sub_sport_flg', \n",
        "                        'mapping_user_prediction_flg', 'mapping_user_national_recipe_flg', 'mapping_user_news_sng_flg', \n",
        "                        'mapping_user_vas_flg', 'mapping_card_mastercard_flg', 'mapping_card_visa_flg', 'mapping_payment_out_3_flg',\n",
        "                        'mapping_payment_out_6_flg', 'mapping_is_top_user_flg', 'mapping_pets_sms_flg', 'mapping_user_health_flg', \n",
        "                        'mapping_cvm_health_flg', 'mapping_webmail_top8_flg', 'mapping_cloud_services_top8_flg', \n",
        "                        'mapping_file_dnld_share_top8_flg', 'mapping_data_traffic_ptl70_flg', 'mapping_mf_tv_mod_flg',\n",
        "                        'mapping_specii_mod_flg', 'mapping_audiobooks_mod_flg', 'mapping_zg_mod_flg', 'mapping_mf_music_mod_flg',\n",
        "                        'mapping_marketplace_mod_flg', 'mapping_pers_gudok_mod_flg', 'mapping_paym_trans_mod_flg', \n",
        "                        'mapping_autopay_mod_flg', 'mapping_paym_transf_forb_mod_flg', 'mapping_pers_gudok_forb_mod_flg', \n",
        "                        'mapping_marketplace_forb_mod_flg', 'mapping_onb_antivir_flg', 'mapping_onb_zoo_flg', \n",
        "                        'mapping_onb_med_online_flg', 'mapping_onb_fitness_flg', 'mapping_onb_edu_online_flg', \n",
        "                        'mapping_onb_books_flg', 'mapping_onb_audiobooks_flg', 'mapping_onb_edu_tech_flg', 'mapping_onb_psyhology_flg',\n",
        "                        'mapping_onb_int_shop_flg', 'mapping_onb_food_delivery_flg', 'mapping_onb_dress_flg', 'mapping_onb_tech_flg', \n",
        "                        'mapping_onb_flower_flg', 'mapping_onb_home_flg', 'mapping_onb_music_flg', 'mapping_onb_movie_flg', \n",
        "                        'mapping_onb_video_flg', 'mapping_onb_games_flg', 'mapping_onb_fashion_flg', 'mapping_onb_bcard_flg', \n",
        "                        'mapping_onb_cashback_flg', 'mapping_onb_payments_flg', 'mapping_onb_insurance_flg', 'mapping_is_male_flg', \n",
        "                        'mapping_specii_v2_flg', 'mapping_megadisk_flg', 'mapping_mf_tv_v2_flg', 'mapping_mf_music_v2_flg', \n",
        "                        'mapping_paym_transf_v2_flg', 'mapping_zg_v2_flg']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_aI37R9UW7P"
      },
      "outputs": [],
      "source": [
        "cat_features = [i for i in categorical_features if i in train.columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eovbd1cuUW7P"
      },
      "outputs": [],
      "source": [
        "len(cat_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1s280_CUW7P"
      },
      "outputs": [],
      "source": [
        "import category_encoders as ce "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK4mSnWZUW7Q"
      },
      "outputs": [],
      "source": [
        "ce.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKnuE_6HUW7Q"
      },
      "outputs": [],
      "source": [
        "cbe_encoder = ce.cat_boost.CatBoostEncoder(cols = cat_features)\n",
        "cbe_encoder.fit_transform(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veoMV69fUW7R"
      },
      "outputs": [],
      "source": [
        "#X_train = cbe_encoder.transform(X_train)\n",
        "X_test = cbe_encoder.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpuceY7iUW7R"
      },
      "outputs": [],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdDwRxfQUW7S"
      },
      "outputs": [],
      "source": [
        "X_eval = cbe_encoder.transform(X_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCbtCI6KUW7S"
      },
      "outputs": [],
      "source": [
        "eval_set = [(X_eval, y_eval)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_rTOhcLUW7S"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "xgb_cl = xgb.XGBClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4g5RBKi5UW7T"
      },
      "outputs": [],
      "source": [
        "xgb_cl.fit(X_train, y_train,eval_metric=\"error\", eval_set=eval_set, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwpVWicWUW7T"
      },
      "outputs": [],
      "source": [
        "with open('xgb_base_pipe_.pkl', 'wb') as file:\n",
        "    pickle.dump(xgb_cl, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLRS8JUfUW7U"
      },
      "outputs": [],
      "source": [
        "preds = xgb_cl.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ady79jyrUW7U"
      },
      "outputs": [],
      "source": [
        "preds_u_i = X_test[['user_id', 'item_id']]\n",
        "preds_u_i['pred'] = preds[:,1:].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WPSxFV6UW7V"
      },
      "outputs": [],
      "source": [
        "preds_u_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEV4EHmwUW7V"
      },
      "outputs": [],
      "source": [
        "preds_u_i.sort_values(['pred'],ascending=False).groupby('user_id').head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAGcSyAjUW7W"
      },
      "outputs": [],
      "source": [
        "preds_u_i[preds_u_i['user_id'] == 559210923.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd18XVe8UW7W"
      },
      "outputs": [],
      "source": [
        "print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MY03d9qUW7X"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjiAciSCUW7X"
      },
      "outputs": [],
      "source": [
        "preds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNdrqSqZUW7Y"
      },
      "outputs": [],
      "source": [
        "accuracy_score(y_test, preds[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2MlilP1UW7Y"
      },
      "outputs": [],
      "source": [
        "mapper = {i: v for i, v in zip(X_train.columns, xgb_cl.feature_importances_)}\n",
        "n_feature = 50\n",
        "\n",
        "feats_1 = pd.DataFrame(list(mapper.items())).sort_values([1],ascending=False)\n",
        "feats_1.set_index([0])[:n_feature].sort_values([1],ascending=True).plot(figsize=(18, 18), kind='barh');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crlbXHNMUW7Z"
      },
      "outputs": [],
      "source": [
        "import shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwWNwktiUW7Z"
      },
      "outputs": [],
      "source": [
        "shap.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SP6vhlLJUW7Z"
      },
      "outputs": [],
      "source": [
        "shap.initjs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJm942leUW7a"
      },
      "outputs": [],
      "source": [
        "explainer = shap.TreeExplainer(xgb_cl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYflHSxEUW7a"
      },
      "outputs": [],
      "source": [
        "shap_values = explainer.shap_values(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRX7mbqyUW7a"
      },
      "outputs": [],
      "source": [
        "shap.summary_plot(shap_values, max_display = 30, features = X_test , feature_names = X_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRG0nyX3UW7b"
      },
      "outputs": [],
      "source": [
        "X_test_real_positives_date.id_offer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXVR9ZuIUW7b"
      },
      "outputs": [],
      "source": [
        "X_train_positives_date.id_offer.plot.density(color='green')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfWJNG4WUW7c"
      },
      "outputs": [],
      "source": [
        "df_train.id_offer.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjIJ5TcXUW7d"
      },
      "outputs": [],
      "source": [
        "X_test_real_positives_date.id_offer.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpEq-WlNUW7e"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df_train.id_offer, hist=True, kde=False, \n",
        "              color = 'blue',\n",
        "             hist_kws={'edgecolor':'black'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAiDFOBjUW7e"
      },
      "outputs": [],
      "source": [
        "X_test_real_positives_date.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXwAJ8QFUW7e"
      },
      "outputs": [],
      "source": [
        "df_ = X_train[X_train['target'] == 1].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hf0wdEJyUW7f"
      },
      "outputs": [],
      "source": [
        "df_['ind'] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZgn9vIVUW7f"
      },
      "outputs": [],
      "source": [
        "df_[['ind','item_id']].groupby('item_id').count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "233f9omcUW7f"
      },
      "source": [
        "## Закончили обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSyKddBFUW7g"
      },
      "outputs": [],
      "source": [
        " score_df = lfm_model.predict(data_test_users =  X_test_real_prep_positives[user_cols + [user_id_col]],\n",
        "                            data_test_items =   X_test_real_prep_date[item_cols + [item_id_col]].drop_duplicates(['id_offer']),\n",
        "                            n_jobs = 40,\n",
        "                            mode = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sV_4lIPUW7g"
      },
      "outputs": [],
      "source": [
        "X_test_real_prep_date = X_test_real_prep_date.rename(columns={\"sk_subs_id\": \"user_id\", \"id_offer\": \"item_id\"})\n",
        "X_test_real_prep_positives = X_test_real_prep_positives.rename(columns={\"sk_subs_id\": \"user_id\", \"id_offer\": \"item_id\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibEyn-w_UW7g"
      },
      "outputs": [],
      "source": [
        "features_ = X_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXrl7wGdUW7h"
      },
      "outputs": [],
      "source": [
        "def accuracy_at_k(users_items_scores_prediction, users_items_real_interactions, \n",
        "                  user_id_column_p, user_id_column_r, \n",
        "                  item_id_column_p, item_id_column_r,\n",
        "                  score_column, k = 5):\n",
        "    '''\n",
        "    Метрика, на основе которой можно проверить качество предсказания и ранжирования.\n",
        "    Принимает на вход датафрейм с результатами предсказаний модели и датафрейм с \n",
        "    парами пользователь-сущность, когда был положительный отклик.\n",
        "    Возвращает долю попаданий выбранного пользователем объекта в топ k скоров по модели\n",
        "    Требует, чтобы пользователи в датафреймах не повторялись, при этом объекты в \n",
        "    таблице со скорами не должны повторяться в срезе по пользователю\n",
        "    '''\n",
        "    result = {}\n",
        "    data_pred = users_items_scores_prediction.copy()\n",
        "    data_real = users_items_real_interactions.copy()\n",
        "    for (user, df_user) in  data_pred.groupby(user_id_column_p):        \n",
        "        df_top_k = df_user.sort_values(score_column, ascending=False).iloc[:k]\n",
        "        top_k_items = set(df_top_k[item_id_column_p].values)       \n",
        "        real_item_id = data_real[item_id_column_r][data_real[user_id_column_r] == user].values[0]      \n",
        "        if real_item_id in top_k_items:\n",
        "            result[user] = 1\n",
        "        else: \n",
        "            result[user] = 0\n",
        "    #print(result)\n",
        "    return np.sum(list(result.values())) / len(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QohvsDV2UW7h"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "acc_at_3_list = []\n",
        "acc_at_5_list = []\n",
        "acc_at_10_list = []\n",
        "for (date, df_date), (date1, df_pos_date) in zip(X_test_real_all_date.groupby('start_date'),\n",
        "                                               X_test_real_positives_date.groupby('start_date')):\n",
        "    assert date1 == date\n",
        "    print(pd.to_datetime(date, unit='s'))\n",
        "    X_test_real_mapping = df_date[item_cols + [item_id_col]].drop_duplicates()\n",
        "    print(X_test_real_mapping.shape)\n",
        "    \n",
        "    user_df = df_pos_date.copy()[user_cols + [user_id_col]]\n",
        "    items_df = X_test_real_mapping.copy()    \n",
        "    \n",
        "    \n",
        "\n",
        "    X_test_real_prep_date = pd.concat([lfm_model.transform(df_date.drop(['target', 'start_date'], axis = 1)),\n",
        "                                   df_date[['start_date']]], axis = 1)\n",
        "    X_test_real_prep_positives = pd.concat([lfm_model.transform(df_pos_date.drop('start_date', axis = 1)),\n",
        "                                        df_pos_date[['start_date']]], axis = 1)\n",
        "    \n",
        "    \n",
        "    score_df = lfm_model.predict(data_test_users =  X_test_real_prep_positives[user_cols + [user_id_col]],\n",
        "                            data_test_items = X_test_real_prep_date[item_cols + [item_id_col]].drop_duplicates(['id_offer']),\n",
        "                            n_jobs = 40,\n",
        "                            mode = 0)\n",
        "    \n",
        "    user_id, id_offer = train_xgb_prepare(score_df)\n",
        "    \n",
        "    score_df['user_id'] = user_id\n",
        "    score_df['item_id'] = id_offer\n",
        "   \n",
        "    score_df['rank'] = score_df.sort_values(['score'], ascending=[False]) \\\n",
        "             .groupby(['user_id']) \\\n",
        "             .cumcount() + 1\n",
        "\n",
        "    score_df = score_df[score_df['rank'] <= 10]\n",
        "    \n",
        "    user_id_column = score_df['user_id']\n",
        "    id_offer_column = score_df['item_id']\n",
        "    \n",
        "    user_df_join = user_df.copy()\n",
        "    items_df_join = items_df.copy()\n",
        "    \n",
        "    \n",
        "    user_df_join = user_df_join.rename(columns={\"sk_subs_id\": \"user_id\", \"id_offer\": \"item_id\"})\n",
        "    items_df_join = items_df_join.rename(columns={\"sk_subs_id\": \"user_id\", \"id_offer\": \"item_id\"})\n",
        "    \n",
        "    \n",
        "    \n",
        "    #Джоин признаков офферов\n",
        "    score_df = score_df.merge(\n",
        "      items_df_join.drop_duplicates(['item_id']), how='left', \n",
        "      on=['item_id'], indicator=True)\n",
        "\n",
        "    #Джоин признаков юзеров \n",
        "    score_df = score_df.merge(\n",
        "        user_df_join, how='inner', \n",
        "        on=['user_id'])\n",
        "    \n",
        "    score_df = score_df.loc[:, score_df.columns.isin(features_)]\n",
        "   \n",
        "    \n",
        "    score_df = cbe_encoder.transform(score_df)\n",
        "    \n",
        "    preds = xgb_cl.predict_proba(score_df)\n",
        "    \n",
        "    \n",
        "    user_id_column = user_id_column.reset_index(drop= True)\n",
        "    id_offer_column = id_offer_column.reset_index(drop = True)\n",
        "    preds = pd.Series(preds[:,1:].flatten()).reset_index(drop = True)\n",
        "\n",
        "    users_items_scores_prediction = pd.DataFrame({'user_id': user_id_column, 'id_offer': id_offer_column, 'score':preds})\n",
        "    \n",
        "    users_items_real_interactions = df_pos_date[['sk_subs_id', 'id_offer']] \n",
        "   # print(users_items_real_interactions)\n",
        "    \n",
        "    acc_at_3 = accuracy_at_k(users_items_scores_prediction, users_items_real_interactions, \n",
        "                             user_id_column_p = 'user_id', user_id_column_r = 'sk_subs_id', \n",
        "                             item_id_column_p = 'id_offer', item_id_column_r = 'id_offer',\n",
        "                             score_column = 'score', k = 3)    \n",
        "    acc_at_3_list.append(acc_at_3)                                           \n",
        "                                                \n",
        "    acc_at_5 = accuracy_at_k(users_items_scores_prediction, users_items_real_interactions, \n",
        "                              user_id_column_p = 'user_id', user_id_column_r = 'sk_subs_id', \n",
        "                             item_id_column_p = 'id_offer', item_id_column_r = 'id_offer',\n",
        "                             score_column = 'score', k = 5)    \n",
        "    acc_at_5_list.append(acc_at_5)    \n",
        "                                                \n",
        "    acc_at_10 = accuracy_at_k(users_items_scores_prediction, users_items_real_interactions, \n",
        "                              user_id_column_p = 'user_id', user_id_column_r = 'sk_subs_id', \n",
        "                             item_id_column_p = 'id_offer', item_id_column_r = 'id_offer',\n",
        "                             score_column = 'score', k = 10)    \n",
        "    acc_at_10_list.append(acc_at_10) \n",
        "\n",
        "print('ok')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YONIPj-bUW7i"
      },
      "outputs": [],
      "source": [
        "print(acc_at_3_list)\n",
        "print(acc_at_5_list)\n",
        "print(acc_at_10_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBLagsbRUW7n"
      },
      "source": [
        "## Проведем подбор гиперпараметров "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAQEcci-UW7n"
      },
      "source": [
        "## Распределение офферов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPWAbmhLUW7o"
      },
      "outputs": [],
      "source": [
        "def accuracy_at_k(users_items_scores_prediction, users_items_real_interactions, \n",
        "                  user_id_column_p, user_id_column_r, \n",
        "                  item_id_column_p, item_id_column_r,\n",
        "                  score_column, k = 5):\n",
        "    '''\n",
        "    Метрика, на основе которой можно проверить качество предсказания и ранжирования.\n",
        "    Принимает на вход датафрейм с результатами предсказаний модели и датафрейм с \n",
        "    парами пользователь-сущность, когда был положительный отклик.\n",
        "    Возвращает долю попаданий выбранного пользователем объекта в топ k скоров по модели\n",
        "    Требует, чтобы пользователи в датафреймах не повторялись, при этом объекты в \n",
        "    таблице со скорами не должны повторяться в срезе по пользователю\n",
        "    '''\n",
        "    result = {}\n",
        "    of_density = {}\n",
        "    data_pred = users_items_scores_prediction.copy()\n",
        "    #print(data_pred)\n",
        "    data_real = users_items_real_interactions.copy()\n",
        "    for (user, df_user) in  data_pred.groupby(user_id_column_p):        \n",
        "        df_top_k = df_user.sort_values(score_column, ascending=False).iloc[:k]\n",
        "        top_k_items = set(df_top_k[item_id_column_p].values)       \n",
        "        real_item_id = data_real[item_id_column_r][data_real[user_id_column_r] == user].values[0]      \n",
        "        if real_item_id in top_k_items:\n",
        "            result[user] = 1\n",
        "        else:\n",
        "            result[user] = 0\n",
        "    #print(result)\n",
        "        of_density[user] = top_k_items\n",
        "        #of_density[str(user) + '_' + str(real_item_id)] = real_item_id\n",
        "        \n",
        "    return np.sum(list(result.values())) / len(result), of_density"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqoFT7PAUW7o"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "acc_at_3_list = []\n",
        "acc_at_5_list = []\n",
        "acc_at_10_list = []\n",
        "of_density_1 = dict()\n",
        "of_density_3 = dict()\n",
        "of_density_5 = dict()\n",
        "of_density_10 = dict()\n",
        "score_table = pd.DataFrame(columns = ['user_id','id_offer','score'])\n",
        "\n",
        "for (date, df_date), (date1, df_pos_date) in zip(X_test_real_all_date.groupby('start_date'),\n",
        "                                               X_test_real_positives_date.groupby('start_date')):\n",
        "    assert date1 == date\n",
        "    print(pd.to_datetime(date, unit='s'))\n",
        "    X_test_real_mapping = df_date[item_cols + [item_id_col]].drop_duplicates()\n",
        "    print(X_test_real_mapping.shape)\n",
        "    \n",
        "    user_df = df_pos_date.copy()[user_cols + [user_id_col]]\n",
        "    items_df = X_test_real_mapping.copy()    \n",
        "    \n",
        "    \n",
        "\n",
        "    X_test_real_prep_date = pd.concat([lfm_model.transform(df_date.drop(['target', 'start_date'], axis = 1)),\n",
        "                                   df_date[['start_date']]], axis = 1)\n",
        "    X_test_real_prep_positives = pd.concat([lfm_model.transform(df_pos_date.drop('start_date', axis = 1)),\n",
        "                                        df_pos_date[['start_date']]], axis = 1)\n",
        "    \n",
        "    \n",
        "    score_df = lfm_model.predict(data_test_users =  X_test_real_prep_positives[user_cols + [user_id_col]],\n",
        "                            data_test_items = X_test_real_prep_date[item_cols + [item_id_col]].drop_duplicates(['id_offer']),\n",
        "                            n_jobs = 40,\n",
        "                            mode = 0)\n",
        "    \n",
        "    user_id, id_offer = train_xgb_prepare(score_df)\n",
        "    \n",
        "    score_df['user_id'] = user_id\n",
        "    score_df['item_id'] = id_offer\n",
        "   \n",
        "    score_df['rank'] = score_df.sort_values(['score'], ascending=[False]) \\\n",
        "             .groupby(['user_id']) \\\n",
        "             .cumcount() + 1\n",
        "\n",
        "    score_df = score_df[score_df['rank'] <= 10]\n",
        "    \n",
        "    user_id_column = score_df['user_id']\n",
        "    id_offer_column = score_df['item_id']\n",
        "    \n",
        "    user_df_join = user_df.copy()\n",
        "    items_df_join = items_df.copy()\n",
        "    \n",
        "    \n",
        "    user_df_join = user_df_join.rename(columns={\"sk_subs_id\": \"user_id\", \"id_offer\": \"item_id\"})\n",
        "    items_df_join = items_df_join.rename(columns={\"sk_subs_id\": \"user_id\", \"id_offer\": \"item_id\"})\n",
        "    \n",
        "    \n",
        "    \n",
        "    #Джоин признаков офферов\n",
        "    score_df = score_df.merge(\n",
        "      items_df_join.drop_duplicates(['item_id']), how='left', \n",
        "      on=['item_id'], indicator=True)\n",
        "\n",
        "    #Джоин признаков юзеров \n",
        "    score_df = score_df.merge(\n",
        "        user_df_join, how='inner', \n",
        "        on=['user_id'])\n",
        "    \n",
        "    score_df = score_df.loc[:, score_df.columns.isin(features_)]\n",
        "   \n",
        "    \n",
        "    score_df = cbe_encoder.transform(score_df)\n",
        "    \n",
        "    preds = xgb_cl.predict_proba(score_df)\n",
        "    \n",
        "    \n",
        "    user_id_column = user_id_column.reset_index(drop= True)\n",
        "    id_offer_column = id_offer_column.reset_index(drop = True)\n",
        "    preds = pd.Series(preds[:,1:].flatten()).reset_index(drop = True)\n",
        "\n",
        "    users_items_scores_prediction = pd.DataFrame({'user_id': user_id_column, 'id_offer': id_offer_column, 'score':preds})\n",
        "    \n",
        "    users_items_real_interactions = df_pos_date[['sk_subs_id', 'id_offer']] \n",
        "   # print(users_items_real_interactions)\n",
        "    \n",
        "    \n",
        "    \n",
        "    _, of_density_1_temp = accuracy_at_k(users_items_scores_prediction, users_items_real_interactions, \n",
        "                             user_id_column_p = 'user_id', user_id_column_r = 'sk_subs_id', \n",
        "                             item_id_column_p = 'id_offer', item_id_column_r = 'id_offer',\n",
        "                             score_column = 'score', k = 1)   \n",
        "    acc_at_3, of_density_3_temp = accuracy_at_k(users_items_scores_prediction, users_items_real_interactions, \n",
        "                             user_id_column_p = 'user_id', user_id_column_r = 'sk_subs_id', \n",
        "                             item_id_column_p = 'id_offer', item_id_column_r = 'id_offer',\n",
        "                             score_column = 'score', k = 3)    \n",
        "    acc_at_3_list.append(acc_at_3)                                           \n",
        "                                                \n",
        "    acc_at_5, of_density_5_temp = accuracy_at_k(users_items_scores_prediction, users_items_real_interactions, \n",
        "                              user_id_column_p = 'user_id', user_id_column_r = 'sk_subs_id', \n",
        "                             item_id_column_p = 'id_offer', item_id_column_r = 'id_offer',\n",
        "                             score_column = 'score', k = 5)    \n",
        "    acc_at_5_list.append(acc_at_5)    \n",
        "                                                \n",
        "    acc_at_10, of_density_10_temp = accuracy_at_k(users_items_scores_prediction, users_items_real_interactions, \n",
        "                              user_id_column_p = 'user_id', user_id_column_r = 'sk_subs_id', \n",
        "                             item_id_column_p = 'id_offer', item_id_column_r = 'id_offer',\n",
        "                             score_column = 'score', k = 10)    \n",
        "    acc_at_10_list.append(acc_at_10) \n",
        "    #print((of_density_3_temp))\n",
        "    of_density_1.update(of_density_1_temp)\n",
        "    of_density_3.update(of_density_3_temp)\n",
        "    of_density_5.update(of_density_5_temp)\n",
        "    of_density_10.update(of_density_10_temp)\n",
        "   #print(of_density_3)\n",
        "   \n",
        "print('ok')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wwvm6a27UW7p"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMz14vuEUW7p"
      },
      "outputs": [],
      "source": [
        "def offer_distribution(of_density):\n",
        "    density = dict()\n",
        "    for user in X_test_real_positives_date.sk_subs_id:\n",
        "        #print(user)\n",
        "        temp = list(of_density[user])\n",
        "       # print(temp[0])\n",
        "        for k in range(len(temp)) :\n",
        "           \n",
        "            if temp[k] in density :\n",
        "                density[temp[k]] += 1\n",
        "            else :\n",
        "                density[temp[k]] = 1\n",
        "                \n",
        "    density = {k: v for k, v in sorted(density.items(), key=lambda item: item[1], reverse = True)}\n",
        "    \n",
        "    print(density)\n",
        "    offer_list = []\n",
        "    offer_list = [key for key in density]\n",
        "    print(offer_list)\n",
        "    num_for_offer = [value for value in density.values()]\n",
        "    offer_list_head = [(offer_name[offer_name['PULL_OFFER_ID'] == i].PULL_OFFER_NAME).values for i in offer_list ]  \n",
        "    #print(offer_list_head)\n",
        "    offer_list_head = [i[0][:30] for i in offer_list_head]\n",
        "    plt.figure(figsize=(7, 10))\n",
        "    plot = sns.barplot( x = num_for_offer , y =  offer_list_head)\n",
        "    count = 0 \n",
        "    for i in offer_list_head :\n",
        "        count +=1\n",
        "        print(f'{count}',i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQb0pXHuUW7q"
      },
      "outputs": [],
      "source": [
        "offer_distribution(of_density_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkegNbkSUW7q"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6",
      "language": "python36",
      "name": "python3.6"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "your_second_rec (1).ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}